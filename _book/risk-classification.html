<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Loss Data Analytics</title>
  <meta name="description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Loss Data Analytics" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Loss Data Analytics" />
  
  <meta name="twitter:description" content="Loss Data Analytics is an interactive, online, freely available text. - The online version will contain many interactive objects (quizzes, computer demonstrations, interactive graphs, video, and the like) to promote deeper learning. - A subset of the book will be available in pdf format for low-cost printing. - The online text will be available in multiple languages to promote access to a worldwide audience." />
  

<meta name="author" content="An open text authored by the Actuarial Community">


<meta name="date" content="2018-05-19">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="aggregate-loss-models.html">
<link rel="next" href="data-systems.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
</script>
<script language="javascript">
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
</script>
<script language="javascript">
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
</script>
<script language="javascript">
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
</script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Loss Data Analytics</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html"><i class="fa fa-check"></i><b>1</b> Aggregate Loss Models</a><ul>
<li class="chapter" data-level="1.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#individual-risk-model"><i class="fa fa-check"></i><b>1.2</b> Individual Risk Model</a></li>
<li class="chapter" data-level="1.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#collective-risk-model"><i class="fa fa-check"></i><b>1.3</b> Collective Risk Model</a><ul>
<li class="chapter" data-level="1.3.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#moments-and-distribution"><i class="fa fa-check"></i><b>1.3.1</b> Moments and Distribution</a></li>
<li class="chapter" data-level="1.3.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#stop-loss-insurance"><i class="fa fa-check"></i><b>1.3.2</b> Stop-loss Insurance</a></li>
<li class="chapter" data-level="1.3.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#analytic-results"><i class="fa fa-check"></i><b>1.3.3</b> Analytic Results</a></li>
<li class="chapter" data-level="1.3.4" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#tweedie-distribution"><i class="fa fa-check"></i><b>1.3.4</b> Tweedie Distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#computing-the-aggregate-claims-distribution"><i class="fa fa-check"></i><b>1.4</b> Computing the Aggregate Claims Distribution</a><ul>
<li class="chapter" data-level="1.4.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#recursive-method"><i class="fa fa-check"></i><b>1.4.1</b> Recursive Method</a></li>
<li class="chapter" data-level="1.4.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#simulation"><i class="fa fa-check"></i><b>1.4.2</b> Simulation</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#effects-of-coverage-modifications"><i class="fa fa-check"></i><b>1.5</b> Effects of Coverage Modifications</a><ul>
<li class="chapter" data-level="1.5.1" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-exposure-on-frequency"><i class="fa fa-check"></i><b>1.5.1</b> Impact of Exposure on Frequency</a></li>
<li class="chapter" data-level="1.5.2" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-deductibles-on-claim-frequency"><i class="fa fa-check"></i><b>1.5.2</b> Impact of Deductibles on Claim Frequency</a></li>
<li class="chapter" data-level="1.5.3" data-path="aggregate-loss-models.html"><a href="aggregate-loss-models.html#impact-of-policy-modifications-on-aggregate-claims"><i class="fa fa-check"></i><b>1.5.3</b> Impact of Policy Modifications on Aggregate Claims</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="risk-classification.html"><a href="risk-classification.html"><i class="fa fa-check"></i><b>2</b> Risk classification</a><ul>
<li class="chapter" data-level="2.1" data-path="risk-classification.html"><a href="risk-classification.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression-model"><i class="fa fa-check"></i><b>2.2</b> Poisson regression model</a><ul>
<li class="chapter" data-level="2.2.1" data-path="risk-classification.html"><a href="risk-classification.html#S:Need.Poi.reg"><i class="fa fa-check"></i><b>2.2.1</b> Need of Poisson regression</a></li>
<li class="chapter" data-level="2.2.2" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression"><i class="fa fa-check"></i><b>2.2.2</b> Poisson regression</a></li>
<li class="chapter" data-level="2.2.3" data-path="risk-classification.html"><a href="risk-classification.html#incorporating-exposure"><i class="fa fa-check"></i><b>2.2.3</b> Incorporating exposure</a></li>
<li class="chapter" data-level="2.2.4" data-path="risk-classification.html"><a href="risk-classification.html#exercises"><i class="fa fa-check"></i><b>2.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="risk-classification.html"><a href="risk-classification.html#categorical-variables-and-multiplicative-tariff"><i class="fa fa-check"></i><b>2.3</b> Categorical variables and multiplicative tariff</a><ul>
<li class="chapter" data-level="2.3.1" data-path="risk-classification.html"><a href="risk-classification.html#rating-factors-and-tariff"><i class="fa fa-check"></i><b>2.3.1</b> Rating factors and tariff</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="risk-classification.html"><a href="risk-classification.html#multiplicative-tariff-model"><i class="fa fa-check"></i><b>2.4</b> Multiplicative tariff model</a><ul>
<li class="chapter" data-level="2.4.1" data-path="risk-classification.html"><a href="risk-classification.html#poisson-regression-for-multiplicative-tariff"><i class="fa fa-check"></i><b>2.4.1</b> Poisson regression for multiplicative tariff</a></li>
<li class="chapter" data-level="2.4.2" data-path="risk-classification.html"><a href="risk-classification.html#numerical-examples"><i class="fa fa-check"></i><b>2.4.2</b> Numerical examples</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="risk-classification.html"><a href="risk-classification.html#further-reading-and-references"><i class="fa fa-check"></i><b>2.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="2.6" data-path="risk-classification.html"><a href="risk-classification.html#S:mle.Pois.reg"><i class="fa fa-check"></i><b>2.6</b> Technical supplements – Estimating Poisson regression model</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-systems.html"><a href="data-systems.html"><i class="fa fa-check"></i><b>3</b> Data Systems</a><ul>
<li class="chapter" data-level="3.1" data-path="data-systems.html"><a href="data-systems.html#data"><i class="fa fa-check"></i><b>3.1</b> Data</a><ul>
<li class="chapter" data-level="3.1.1" data-path="data-systems.html"><a href="data-systems.html#data-types-and-sources"><i class="fa fa-check"></i><b>3.1.1</b> Data Types and Sources</a></li>
<li class="chapter" data-level="3.1.2" data-path="data-systems.html"><a href="data-systems.html#data-structures-and-storage"><i class="fa fa-check"></i><b>3.1.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="3.1.3" data-path="data-systems.html"><a href="data-systems.html#data-quality"><i class="fa fa-check"></i><b>3.1.3</b> Data Quality</a></li>
<li class="chapter" data-level="3.1.4" data-path="data-systems.html"><a href="data-systems.html#data-cleaning"><i class="fa fa-check"></i><b>3.1.4</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="data-systems.html"><a href="data-systems.html#data-analysis-preliminary"><i class="fa fa-check"></i><b>3.2</b> Data Analysis Preliminary</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-systems.html"><a href="data-systems.html#S:process"><i class="fa fa-check"></i><b>3.2.1</b> Data Analysis Process</a></li>
<li class="chapter" data-level="3.2.2" data-path="data-systems.html"><a href="data-systems.html#exploratory-versus-confirmatory"><i class="fa fa-check"></i><b>3.2.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="3.2.3" data-path="data-systems.html"><a href="data-systems.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>3.2.3</b> Supervised versus Unsupervised</a></li>
<li class="chapter" data-level="3.2.4" data-path="data-systems.html"><a href="data-systems.html#parametric-versus-nonparametric"><i class="fa fa-check"></i><b>3.2.4</b> Parametric versus Nonparametric</a></li>
<li class="chapter" data-level="3.2.5" data-path="data-systems.html"><a href="data-systems.html#S:expred"><i class="fa fa-check"></i><b>3.2.5</b> Explanation versus Prediction</a></li>
<li class="chapter" data-level="3.2.6" data-path="data-systems.html"><a href="data-systems.html#data-modeling-versus-algorithmic-modeling"><i class="fa fa-check"></i><b>3.2.6</b> Data Modeling versus Algorithmic Modeling</a></li>
<li class="chapter" data-level="3.2.7" data-path="data-systems.html"><a href="data-systems.html#big-data-analysis"><i class="fa fa-check"></i><b>3.2.7</b> Big Data Analysis</a></li>
<li class="chapter" data-level="3.2.8" data-path="data-systems.html"><a href="data-systems.html#reproducible-analysis"><i class="fa fa-check"></i><b>3.2.8</b> Reproducible Analysis</a></li>
<li class="chapter" data-level="3.2.9" data-path="data-systems.html"><a href="data-systems.html#ethical-issues"><i class="fa fa-check"></i><b>3.2.9</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-systems.html"><a href="data-systems.html#data-analysis-techniques"><i class="fa fa-check"></i><b>3.3</b> Data Analysis Techniques</a><ul>
<li class="chapter" data-level="3.3.1" data-path="data-systems.html"><a href="data-systems.html#exploratory-techniques"><i class="fa fa-check"></i><b>3.3.1</b> Exploratory Techniques</a></li>
<li class="chapter" data-level="3.3.2" data-path="data-systems.html"><a href="data-systems.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Descriptive Statistics</a></li>
<li class="chapter" data-level="3.3.3" data-path="data-systems.html"><a href="data-systems.html#cluster-analysis"><i class="fa fa-check"></i><b>3.3.3</b> Cluster Analysis</a></li>
<li class="chapter" data-level="3.3.4" data-path="data-systems.html"><a href="data-systems.html#confirmatory-techniques"><i class="fa fa-check"></i><b>3.3.4</b> Confirmatory Techniques</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="data-systems.html"><a href="data-systems.html#some-r-functions"><i class="fa fa-check"></i><b>3.4</b> Some R Functions</a></li>
<li class="chapter" data-level="3.5" data-path="data-systems.html"><a href="data-systems.html#summary"><i class="fa fa-check"></i><b>3.5</b> Summary</a></li>
<li class="chapter" data-level="3.6" data-path="data-systems.html"><a href="data-systems.html#further-resources-and-contributors"><i class="fa fa-check"></i><b>3.6</b> Further Resources and Contributors</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://ewfrees.github.io/Loss-Data-Analytics/" target="blank">Loss Data Analytics on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Loss Data Analytics</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="risk-classification" class="section level1">
<h1><span class="header-section-number">Chapter 2</span> Risk classification</h1>
<p><em>Chapter Preview.</em> This chapter motivates the use of risk classification in insurance pricing and introduces readers to the Poisson regression as a prominent example of risk classification. In Section 1 we explain why insurers need to incorporate various risk characteristics, or rating factors, of individual policyholders in pricing insurance contracts. We then introduce the Poisson regression as a pricing tool to achieve such premium differentials. The concept of exposure is also introduced in this section. As most rating factors are categorical, we show in Section 3 how the multiplicative tariff model can be incorporated in the Poisson regression model in practice, along with numerical examples for illustration.</p>
<!-- %Introduction to risk classification using Poisson regression models -->
<!-- %Exposure to risk -->
<!-- %Categorical variables and multiplicative tariff -->
<!-- %Extensions to generalized linear models -->
<!-- %Technical Supplement 3.  Likelihood and generalized linear models -->
<div id="introduction-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Introduction</h2>
<p>In this section you learn:</p>
<ul>
<li><p>Why premiums should vary across policyholders with different risk characteristics.</p></li>
<li><p>The meaning of the adverse selection spiral.</p></li>
<li><p>The need of risk classification.</p></li>
</ul>
<p>Through insurance contracts, the policyholders effectively transfer their risks to the insurer in exchange for premiums. For the insurer to stay in business, the premium income collected from a pool of policyholders must at least equal to the benefit outgo. Ignoring the frictional expenses associated with the administrative cost and the profit margin, the net premium charged by the insurer thus should be equal to the expected loss occurring from the risk that is transferred from the policyholder.</p>
<p>If all policyholders in the insurance pool have identical risk profiles, the insurer simply charges the same premium for all policyholders because they have the same expected loss. In reality however the policyholders are hardly homogeneous. For example, mortality risk in life insurance depends on the characteristics of the policyholder, such as, age, sex and life style. In auto insurance, those characteristics may include age, occupation, the type or use of the car, and the area where the driver resides. The knowledge of these characteristics or variables can enhance the ability of calculating fair premiums for individual policyholders as they can be used to estimate or predict the expected losses more accurately.</p>
<p>Indeed, if the insurer do not differentiate the risk characteristics of individual policyholders and simply charges the same premium to all insureds based on the average loss in the portfolio, the insurer would face adverse selection, a situation where individuals with a higher chance of loss are attracted in the portfolio and low-risk individuals are repelled. For example, consider a health insurance industry where smoking status is an important risk factor for mortality and morbidity. Most health insurers in the market require different premiums depending on smoking status, so smokers pay higher premiums than non-smokers, with other characteristics being identical. Now suppose that there is an insurer, we will call EquitabAll, that offers the same premium to all insureds regardless of smoking status, unlike other competitors. The net premium of EquitabAll is natually an average mortality loss accounting for both smokers and non-smokers. That is, the net premium is a weighted average of the losses with the weights being the proportion of smokers and non-smokers, respectively. Thus it is easy to see that that a smoker would have a good incentive to purchase insurance from EquitabAll than from other insurers as the offered premium by EquitabAll is relatively lower. At the same time non-smokers would prefer buying insurance from somewhere else where lower premiums, computed from the non-smoker group only, are offered. As a result, there will be more smokers and less non-smokers in the EquitabAll’s portfolio, which leads to larger-than-expected losses and hence a higher premium for insureds in the next period to cover the higher costs. With the raised new premium in the next period, non-smokers in EquitabAll will have even greater incentives to switch the insurer. As this cycle continues over time, EquitabAll would gradually retain more smokers and less non-smokers in its portfolio with the premium continually raised, eventually leading to a collapsing of business. In the literature this phenomenon is known as the <em>adverse selection spiral</em> or death spiral. Therefore, incorporating and differentiating important risk characteristics of individuals in the insurance pricing process are a pertinent component for both the determination of fair premium for individual policyholders and the long term sustainability of insurers.</p>
<!-- % -->
<!-- % -->
<!-- %e common industry-wide net premium rates for smokers and non-smokers are denoted by $P^s$ and $P^{ns}$, respectively, assuming the same underling population and ignoring all the frictional costs. However there is a particular insurer, we will call EquitabAll, that offers the same premium to all insureds regardless of smoking status.   -->
<!-- % -->
<!-- % and B have different premium strategies regarding smoking status, an important risk factor for mortality. Insurer A offers the same premium to all insureds regardless of smoking status, with other characteristics being identical. The net premium, denoted $P_A$, then is the average loss accounting for both smokers and on-smokers. In contrast, insurer B has different premium rates for smokers and non-smokers, denoted $P^s_B$ and $P^{ns}_B$, respectively. We can see that $P^{ns}_B<P_A<P^{s}_B$ for the same underling population when all the frictional costs are ignored.  -->
<!-- %Thus it is apparent that a smoker would have a good incentive to purchase insurance from insurer A than B as the premium offered by the former is lower. At the same time non-smokers would prefer buying insurance from insurer B that offers a lower premium computed from non-smokers only. The result of this tendency for insurer A is that there will be more smokers and less non-smokers in the portfolio, which in turn leads to larger-than-expected mortality losses and therefore a higher premium for insurer A in the next period to cover the higher costs. With the raised new premium, non-smokers in insurer A will now have a greater incentive to switch the insurer. As this cycle continues, thus, insurer A retain more and more smokers with premiums continually raised over time, leading to a collapsing of business eventually. This phenomenon is known as the adverse selection spiral or death spiral. -->
<!-- % -->
<!-- %a considerable . Since the premium of insurer A increases at each cycle, its premium level eventually will  -->
<!-- % -->
<!-- %all non-smokers will leave to find better premiums in other insurers. insurers  can there will be less and less until no one, not even the sick who may strongly want or need it, can afford the policy. The individual health insurance policy group then goes out of existence. Since the original size of the group was small in relation to the total subscriber base, it is very easy for an insurer to eliminate or allow to go out of existence, any one group of policyholders. -->
<!-- % -->
<!-- %more non-smokers will leave and more smokers are  -->
<!-- %it would attract a greater portion of insureds in insurer A  -->
<!-- %continues, the insurer with the non-discriminating premium structure  -->
<p>In order to incorporate relevant risk characteristics of policyholders in the pricing process, insurers maintain some classification system that assigns each policyholder to one of the risk classes based on a relatively small number of risk characteristics that are deemed most relevant. These characteristics used in the classification system are called the <em>rating factors</em>, which are <em>a priori</em> variables in the sense that they are known before the contract begins (e.g., sex, health status, vehicle type, etc, are known during the underwriting). All policyholders sharing identical risk factors thus are assigned to the same risk class, and are considered homogeneous from the pricing viewpoint; the insurer consequently charge them the same premium.</p>
<p>An important task in any risk classification is to construct a quantitative model that can determine the expected loss given various rating factors of a policyholder. The standard approach is to adopt a statistical regression model which produces the expected loss as the output when the relevant risk factors are given as the inputs. In this chapter we learn the Poisson regression, which can be used when the loss is a count variable, as a prominent example of an insurance pricing tool.</p>
<!-- %\subsection{Fundamental concept of insurance pricing} -->
<!-- %================================ -->
</div>
<div id="poisson-regression-model" class="section level2">
<h2><span class="header-section-number">2.2</span> Poisson regression model</h2>
<!-- %================================ -->
<!-- %The Poisson regression model has been successfully used in a wide range of applications and has an advantage of allowing closed-form expressions for the important quantities, which could provide a better intuition. We start our discussion with the standard linear regression model. -->
<!-- %\subsection{Linear regression} -->
<!-- %Suppose that we have a single a priori rating factor denoted $x$ for each policyholder along with the past loss amount, which is also a single number $y$. Then for a pool of $n$ independent policyholders the insurer's dataset consists of $(x_i, y_i)$, $i=1, \ldots,n$, where the subscript indicates the $i$th policyholder. The simplest linear regression model then postulates a linear relation between $x$ and $y$, so that  -->
<!-- %\begin{equation} -->
<!-- %\label{simple.linear.reg} -->
<!-- %y_i=\beta_0+\beta_1x_i+\epsilon_i, \quad i=1, \ldots,n. -->
<!-- %\end{equation} -->
<!-- %Here $\beta_0$ and $\beta_1$ are the common intercept and slope coefficients which apply to all policyholders. The last term $\epsilon_i$, known as the random error term, represents the random uncertainty that cannot be captured by the pure deterministic equation $y=\beta_0+\beta_1x$.  It is commonly assumed that $\epsilon_i \sim_{iid} N(0, \sigma^2)$, so that we have, from (\ref{simple.linear.reg}), -->
<!-- %\begin{equation} -->
<!-- %\label{simple.linear.reg.ft} -->
<!-- %\E(y_i|x_i)=\beta_0+\beta_1x_i. -->
<!-- %\end{equation} A generic form of this model without the subscripts, called the regression or mean response function, is written as -->
<!-- %\begin{equation} -->
<!-- %\label{simple.linear.reg.ft2} -->
<!-- %\E(y|x)=\beta_0+\beta_1x -->
<!-- %\end{equation} -->
<!-- %Thus the \textit{expected} loss $\E(y|x)$ is a linear function of the rating factor $x$. In the statistical literature, the input $x$ is often referred to as the predictor or explanatory variable, and the output $y$ as the response variable. This functional form indicates that when the rating factor $x$ increases by 1, the loss amount increases by $\beta_1$ on average. This formulation however is merely a theoretical one because the true values of $\beta_0$ and $ \beta_0$ are unknown. To obtain a workable model, we estimate these parameters using, e.g., maximum likelihood estimation (mle)\footnote{For the linear regression, the mle and ols yield the same estimators. } based on the normal distributional assumption for $\epsilon_i$. By denoting these estimates by $\hat{\beta}_0=b_0$ and $\hat{\beta}_1=b_1$, we obtain the estimated regression function  -->
<!-- %\begin{equation} -->
<!-- %\label{y.hat.simple.reg} -->
<!-- %\hat{y}_i=b_0+b_1x_i, -->
<!-- %\end{equation} paralleling Equation (\ref{simple.linear.reg.ft}). Thus, if the postulated linear model in (\ref{simple.linear.reg}) is accepted, we can estimate the expected loss for the $i$th policyholders simply as $\hat{y}_i=b_0+b_1x_i$, and policyholders with a different rating factor produces a different premium. -->
<!-- % -->
<!-- %When there are more than one rating factors, as is the case in practice, we extend this simple linear form (\ref{simple.linear.reg}) into a multiple linear regression. When there are $k \ge 1$ different rating factors for each policyholder, the record of the $i$th policyholder would consist of $(x_{i1}, x_{i2}, \ldots , x_{ik}, y_i)$, $i=1, \ldots,n$, and the multiple linear regression postulates -->
<!-- %\begin{equation} -->
<!-- %\label{mult.linear.reg} -->
<!-- %y_i=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\ldots + \beta_k x_{ik}+\epsilon_i, \quad i=1, \ldots,n. -->
<!-- %\end{equation} -->
<!-- %By using matrix notation we can compactly rewrite this model as -->
<!-- %\begin{equation} -->
<!-- %\label{mult.linear.reg.mtx} -->
<!-- %\mathbf{ y}=\mathbf{ X\beta} +\mathbf{ \epsilon} -->
<!-- %\end{equation} -->
<!-- %where each vector and matrix are given by -->
<!-- % \begin{eqnarray*} -->
<!-- %% Y &=& X \beta + \epsilon \\ -->
<!-- %% \noalign{\hbox{where}} -->
<!-- %\mathbf{ y} &=& \left( \begin{array}{c} y_1 \\ y_2 \\ \vdots \\ y_n -->
<!-- %              \end{array} \right), \qquad -->
<!-- %{\beta} = \left( \begin{array}{c} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_{k} -->
<!-- %              \end{array} \right), \qquad -->
<!-- %{\epsilon} = \left( \begin{array}{c} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_n -->
<!-- %              \end{array} \right), \qquad \text{and} \quad -->
<!-- %\mathbf{ X} = \left( \begin{array}{cccc} -->
<!-- %        1 & x_{11} & ... &x_{1k} \\ -->
<!-- %        1 & x_{2}  & ... &x_{2k}\\ -->
<!-- %       \vdots & \vdots  & \ddots  & \vdots \\ -->
<!-- %  %      1 & X_{i1} & X_{i2} & \ldots & X_{ip} \\ -->
<!-- %  %     \vdots & \vdots & \vdots & \vdots  \\ -->
<!-- %        1 & x_{n} & ... &x_{n,k} \end{array} \right)  \\ -->
<!-- % \end{eqnarray*}  -->
<!-- %The corresponding regression function is then given by -->
<!-- %\begin{equation} -->
<!-- %\label{mult.linear.reg.ft3} -->
<!-- %\E({ y}|\mathbf{ x})=\mathbf{ x^{\prime}\beta} -->
<!-- %\end{equation} where $\mathbf{ x}=(1, x_1, \ldots, x_k)^{\prime}$ is the vector of some hypothesized rating factors. As before, the parameter vector $\beta$ must be estimated from the dataset, and one can obtain the estimated regression function  -->
<!-- %\begin{equation} -->
<!-- %\label{mult.linear.reg.ft4} -->
<!-- %\hat{ y}= b_0+b_1 x_1+ \ldots +b_k x_k= \mathbf{ x^{\prime}b}, -->
<!-- %\end{equation} -->
<!-- %where  $\mathbf{ b}=(b_0, \ldots, b_k)^{\prime}=(\hat{\beta}_0, \ldots, \hat{\beta}_k)^{\prime}$.  -->
<!-- % -->
<!-- %The linear regression models are important statistical tools in data analyses and encompass a wide variety of extensions but we do not delve into this too much as our goal here in this chapter is to introduce an alternative regression model that can handle count response variables. -->
<p>The Poisson regression model has been successfully used in a wide range of applications and has an advantage of allowing closed-form expressions for important quantities, which provides a informative intuition and interpretation. In this section we introduce the Poisson regression as a natural extension of the Poisson distribution.</p>
<p>In this section you will:</p>
<ul>
<li><p>Understand Poisson regressions as convenient tool to combine individual Poisson distributions in a unified fashion.</p></li>
<li><p>Learn the concept of exposure and its importance.</p></li>
<li><p>Formally learn how to formulate the Poisson regression model using indicator variables when the explanatory variables are categorical.</p></li>
</ul>
<!-- %------------------------ -->
<div id="S:Need.Poi.reg" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Need of Poisson regression</h3>
<!-- %------------------------ -->
<p><strong>Poisson distribution</strong></p>
<p>To introduce the Poisson regression, let us consider a hypothetical health insurance portfolio where all policyholders are of the same age and only one risk factor, smoking status, is relevant. Smoking status thus is a categorical variable containing two different types: smoker and non-smoker. In the statistical literature different types in a given categorical variable are commonly called <em>levels</em>. As there are two levels for the smoking status, we may denote smoker and non-smoker by level 1 and 2, respectively. Here the numbering is arbitrary and nominal. Suppose now that we are interested in pricing a health insurance where the premium for each policyholder is determined by the number of outpatient visits to doctor’s office during a year. The amount of medical cost for each visit is assumed to be the same regardless of the smoking status for simplicity. Thus if we believe that smoking status is a valid risk factor in this health insurance, it is natural to consider the data separately for each smoking status. In Table 8.1 we present the data for this portfolio. <!-- % --> <!-- %Assuming that there are $n_i$ policies in each status $i =1,2$, we denote the number of visits to doctor's office made by the $j$th policyholder in category $i$  in the last year as $y_{ij}$, which can take values $0,1,2, \ldots$.  --></p>
<p><span class="math display">\[\begin{matrix}
\begin{array}{cc|cc|cc}
\hline
\text{Smoker} &amp; \text{(level 1)}  &amp; \text{Non-smoker}&amp;\text{(level 2)}  &amp; &amp; \text{Both}\\
  \text{Count} &amp; \text{Observed} &amp;  \text{Count} &amp; \text{Observed}  &amp;   \text{Count} &amp; \text{Observed} \\ \hline
0 &amp; 2213 &amp;   0 &amp; 6671 &amp;  0 &amp; 8884 \\
1 &amp; 178  &amp;   1 &amp; 430  &amp;  1 &amp; 608 \\
2 &amp; 11   &amp;   2 &amp; 25   &amp;  2 &amp; 36 \\
3 &amp; 6    &amp;   3 &amp; 9    &amp;  3 &amp; 15 \\
4 &amp; 0    &amp;   4 &amp; 4    &amp;  4 &amp; 4 \\
5 &amp; 1    &amp;   5 &amp; 2    &amp;  5 &amp; 3 \\ \hline
\text{Total} &amp; 2409  &amp;   \text{Total} &amp; 7141 &amp; \text{Total} &amp; 9550 \\
\text{Mean} &amp; 0.0926 &amp;   \text{Mean} &amp; 0.0746 &amp; \text{Mean} &amp; 0.0792 \\
\hline
    \end{array}
\end{matrix}\]</span></p>
<p>[Table 8.1] : Number of visits to doctor’s office in last year</p>
<!-- %In Table \ref{tab.type} we have $n_1=$, $n_2=$ and $n_3=$.  -->
<p>As this dataset contains random counts we try to fit a Poisson distribution for each level.</p>
<p>The pmf of the Poisson with mean <span class="math inline">\(\mu\)</span> is given by <span class="math display">\[\begin{equation}
\Pr(Y=y)=\frac{\mu^y e^{-\mu}}{y!},\qquad y=0,1,2, \ldots  - (1)
\end{equation}\]</span><br />
and <span class="math inline">\(\mathrm{E~}{(Y)}=\mathrm{Var~}{(Y)}=\mu\)</span>. Furthermore, the mle of the Poisson distribution is given by the sample mean. Thus if we denote the Poisson mean parameter for each level by <span class="math inline">\(\mu_{(1)}\)</span> (smoker) and <span class="math inline">\(\mu_{(2)}\)</span> (non-smoker), we see from Table 8.1 that <span class="math inline">\(\hat{\mu}_{(1)}=0.0926\)</span> and <span class="math inline">\(\hat{\mu}_{(2)}=0.0746\)</span>. This simple example shows the basic idea of risk classification. Depending on the smoking status a policyholder will have a different risk characteristic and it can be incorporated through varying Poisson parameter in computing the fair premium. In this example the ratio of expected loss frequencies is <span class="math inline">\(\hat{\mu}_{(1)}/\hat{\mu}_{(2)}=1.2402\)</span>, implying that smokers tend to visit doctor’s office 24.02<span class="math inline">\(\%\)</span> times more frequently compared to non-smokers.</p>
<p>It is also informative to note that if the insurer charges the same premium to all policyholders regardless of the smoking status, based on the average characteristic of the portfolio, as was the case for EquitabAll described in Introduction, the expected frequency (or the premium) <span class="math inline">\(\hat{\mu}\)</span> is 0.0792, obtained from the last column of Table 8.1. It is easily verified that <span class="math display">\[\begin{equation}
\hat{\mu} = \left(\frac{n_1}{n_1+n_2}\right)\hat{\mu}_{(1)}+\left(\frac{n_2}{n_1+n_2}\right)\hat{\mu}_{(2)}=0.0792, - (2)
\end{equation}\]</span><br />
where <span class="math inline">\(n_i\)</span> is the number of observations in each level. Clearly, this premium is a weighted average of the premiums for each level with the weight equal to the proportion of the insureds in that level.</p>
<p><strong>A simple Poisson regression</strong><br />
In the example above, we have fitted a Poisson distribution for each level separately, but we can actually combine them together in a unified fashion so that a single Poisson model can encompass both smoking and non-smoking statuses. This can be done by relating the Poisson mean parameter with the risk factor. In other words, we make the Poisson mean, which is the expected loss frequency, respond to the change in the smoking status. The conventional approach to deal with a categorical variable is to adopt indicator or dummy variables that take either 1 or 0, so that we turn the switch on for one level and off for others. Therefore we may propose to use <span class="math display">\[\begin{equation}
\mu=\beta_0+\beta_1 x_1 - (3)
\end{equation}\]</span> or, more commonly, a log linear form <span class="math display">\[\begin{equation}
\log \mu=\beta_0+\beta_1 x_1, - (4)
\end{equation}\]</span> where <span class="math inline">\(x_1\)</span> is an indicator variable with <span class="math display">\[\begin{equation}
x_1=
\begin{cases}
     1 &amp; \text{if smoker}, \\
     0 &amp; \text{otherwise}.
\end{cases} - (5)
\end{equation}\]</span> We generally prefer the log linear relation (4) to the linear one in (3) to prevent undesirable events of producing negative <span class="math inline">\(\mu\)</span> values, which may happen when there are many different risk factors and levels. The setup (4) and (5) then results in different Poisson frequency parameters depending on the level in the risk factor: <span class="math display">\[\begin{equation}
\log \mu=
\begin{cases}
     \beta_0+\beta_1 \\
     \beta_0 
\end{cases}
\quad \text{or equivalently,}\qquad \mu= \begin{cases}
     e^{\beta_0+\beta_1} &amp; \text{if smoker (level 1)}, \\
     e^{\beta_0} &amp; \text{if non-smoker (level 2)},
\end{cases} - (6)
\end{equation}\]</span> achieving what we aim for. This is the simplest form of the Poisson regression. Note that we require a single indicator variable to model two levels in this case. Alternatively, it is also possible to use two indicator variables through a different coding scheme. This scheme requires dropping the intercept term so that (4) is modified to <span class="math display">\[\begin{equation}
\log \mu=\beta_1 x_1+\beta_2 x_2, - (7)
\end{equation}\]</span> where <span class="math inline">\(x_2\)</span> is the second indicator variable with <span class="math display">\[\begin{equation}
x_2=
\begin{cases}
     1 &amp; \text{if non-smoker}, \\
     0 &amp; \text{otherwise}.
\end{cases} - (8)
\end{equation}\]</span> Then we have, from (7), <span class="math display">\[\begin{equation}
\log \mu=
\begin{cases}
     \beta_1 \\
     \beta_2 
\end{cases}
\quad \text{or}\qquad \mu= \begin{cases}
     e^{\beta_1} &amp; \text{if smoker (level 1)}, \\
     e^{\beta_2} &amp; \text{if non-smoker (level 2)}.
\end{cases} - (9)
\end{equation}\]</span> The numerical result of (6) is the same as (9) as all the coefficients are given as numbers in actual estimation, with the former setup more common in most texts; we also stick to the former.</p>
<p>With this Poisson regression model we can easily understand how the coefficients <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are linked to the expected loss frequency in each level. According to (6), the Poisson mean of the smokers, <span class="math inline">\(\mu_{(1)}\)</span>, is given by <span class="math display">\[\begin{equation}
\mu_{(1)}=e^{\beta_0+\beta_1}=\mu_{(2)} \,e^{\beta_1} \quad \text{or}\quad  \mu_{(1)}/\mu_{(2)} =e^{\beta_1} - (10)
\end{equation}\]</span> where <span class="math inline">\(\mu_{(2)}\)</span> is the Poisson mean for the non-smokers. This relation between the smokers and non-smokers suggests a useful way to compare the risks embedded in different levels of a given risk factor. That is, the proportional increase in the expected loss frequency of the smokers compared to that of the non-smokers is simply given by a multiplicative factor <span class="math inline">\(e^{\beta_1}\)</span>. Putting another way, if we set the expected loss frequency of the non-smokers as the base value, the expected loss frequency of the smokers is obtained by applying <span class="math inline">\(e^{\beta_1}\)</span> to the base value.</p>
<p><strong>Dealing with multi-level case</strong><br />
We can readily extend the two-level case to a multi-level one where <span class="math inline">\(l\)</span> different levels are involved for a single rating factor. For this we generally need <span class="math inline">\(l-1\)</span> indicator variables to formulate <span class="math display">\[\begin{equation}
\log \mu=\beta_0+\beta_1 x_1+\ldots+\beta_{l-1} x_{l-1}, - (11)
\end{equation}\]</span> where <span class="math inline">\(x_k\)</span> is an indicator variable that takes 1 if the policy belongs to level <span class="math inline">\(k\)</span> and 0 otherwise, for <span class="math inline">\(k=1,2, \ldots, l-1\)</span>. By omitting the indicator variable associated with the last level in (11) we effectively chose level <span class="math inline">\(l\)</span> as the base case, but this choice is arbitrary and does not matter numerically. The resulting Poisson parameter for policies in level <span class="math inline">\(k\)</span> then becomes, from (11), <span class="math display">\[\begin{equation}
\nonumber
\mu= \begin{cases}
     e^{\beta_0+\beta_k} &amp; \text{if the policy belongs to level k (k=1,2, ..., l-1)}, \\
     e^{\beta_0} &amp; \text{if the policy belongs to level l}.
\end{cases}
\end{equation}\]</span> Thus if we denote the Poisson parameter for policies in level <span class="math inline">\(k\)</span> by <span class="math inline">\(\mu_{(k)}\)</span>, we can relate the Poisson parameter for different levels through <span class="math inline">\(\mu_{(k)}=\mu_{(l)}\, e^{\beta_k}\)</span>, <span class="math inline">\(k=1,2, \ldots, l-1\)</span>. This indicates that, just like the two-level case, the expected loss frequency of the <span class="math inline">\(k\)</span>th level is obtained from the base value multiplied by the relative factor <span class="math inline">\(e^{\beta_k}\)</span>. This relative interpretation becomes more powerful when there are many risk factors with multi-levels, and leads us to a better understanding of the underlying risk and more accurate prediction of future losses. Finally, we note that the varying Poisson mean is completely driven by the coefficient parameters <span class="math inline">\(\beta_k\)</span>’s, which are to be estimated from the dataset; the procedure of the parameter estimation will be discussed later in this chapter. <!-- % --> <!-- % --> <!-- %We may summarise what we have so far as follows. First, instead of fitting different Poisson distributions for each level of the given categorical variable, we propose to use a unified Poisson model that can incorporate different levels together. Second, in the unified  model we express the Poisson mean $\mu$ as a function of a risk factor. Specifically, we adopt a log linear model (\ref{log.lin.mu}). Third, the output  --></p>
<!-- % -->
<!-- %\subsection{Need of Possion regression model}  -->
<!-- %%------------------------ -->
<!-- %Now suppose that we have a dataset where the response variable is the loss count instead of the loss amount. For example, $y$ can be the number of accidents of a policyholder during a year. In this case the loss can take only non-negative integer values, i.e., $y_i=0,1,2, \ldots$ for each policyholder. Unfortunately, the multiple linear regression above, despite being popular and useful in many applications, cannot handle this  -->
<!-- %type of dataset because of the following reasons. First, there is no guarantee that the output $\hat{y}$ in (\ref{y.hat.simple.reg}) is an integer value. It is easy to imagine that it can be a fractional number by adjusting some rating factors. Second, more importantly, there is possibility that $\hat{y}$ becomes negative for a peculiar set of rating factors. These unintended and undesirable consequences are actually due to the fact that the output of multiple linear regression models spans the whole real line, that is, $\hat{y}$ can take any real value in $(-\infty, \infty)$ by construction. More fundamentally, this stems from the very assumption of the normal error terms in the regression model itself. This can be readily verified by observing that, when  $\epsilon_i \sim_{iid} N(0, \sigma^2)$, the response variable is also normally distributed  according to (\ref{simple.linear.reg}): -->
<!-- %\begin{equation} -->
<!-- %\label{ } -->
<!-- %y_i \sim_{iid} N(\beta_0+\beta_1x_i, \sigma^2), -->
<!-- %\end{equation} -->
<!-- %which confirms that the loss amount $y$ is allowed to take any real value. -->
<!-- % -->
<!-- %One may impose restrictions on the linear regression so that it can take only non-negative integers as the response variable. Instead of seeking such ad hoc solutions however we consider the Poisson regression, a different type of regression model where the underlying random component is consistent with the count variable. We have encountered the Poisson distribution and studied its distributional properties  in early chapters. The pmf of the Poisson with mean $\mu$ is -->
<!-- %\begin{equation} -->
<!-- %\label{Pois.pmf} -->
<!-- %\Pr(Y=y)=\frac{\mu^y e^{-\mu}}{y!},\qquad y=0,1,2, \ldots -->
<!-- %\end{equation} and $\E(Y)=\Var(Y)=\mu$.  -->
<!-- %Now suppose $Y$ stands for the random loss count, and it depends on $k$ rating factors $\mathbf{ x}=(1, x_1, \ldots, x_k)$, as before. Our goal is then to formulate a regression model which uses the Poisson distribution as the response variable and, at the same time, responds to risk factors of individual policyholders.   -->
<!-- % -->
<!-- %two abstraction: -->
<!-- %\\ -->
<!-- %1. matrix representation\\ -->
<!-- %2. below\\ -->
<!-- %(see project webpage to see the notation and basic regression backgrounds) -->
<!-- % -->
<!-- % -->
<!-- %Actually we can see Equation (\ref{simple.linear.reg}) as a special case of the following general form -->
<!-- %\begin{equation} -->
<!-- %\label{ } -->
<!-- %y_i=f(x_i)+\epsilon_i -->
<!-- %\end{equation} -->
<!-- %By adopting different functions $f$, one can build a wide range of different models, though the validity and suitability of those models needs to be statistically addressed.  -->
<!-- % -->
<!-- %To fix the notation we assume: -->
<!-- % -->
</div>
<div id="poisson-regression" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Poisson regression</h3>
<p>We now describe the Poisson regression in a formal and more general setting. Let us assume that there are <span class="math inline">\(n\)</span> independent policyholders with a set of rating factors characterized by a <span class="math inline">\(k\)</span>-variate vector<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a>. The <span class="math inline">\(i\)</span>th policyholder’s rating factor is thus denoted by vector <span class="math inline">\(\mathbf{ x}_i=(1, x_{i1}, \ldots, x_{ik})^{\prime}\)</span>, and the policyholder has recorded the loss count <span class="math inline">\(y_i \in \{0,1,2, \ldots \}\)</span> from the last period of loss observation, for <span class="math inline">\(i=1, \ldots, n\)</span>. In the regression literature, the values <span class="math inline">\(x_{i1}, \ldots, x_{ik}\)</span> are generally known as the <em>explanatory variables</em>, as these are measurements providing information about the variable of interest <span class="math inline">\(y_i\)</span>. In essence, regression analysis is a method to quantify the relationship between a variable of interest and explanatory variables.</p>
<p>We also assume, for now, that all policyholders have the same one unit period for loss observation, or equal exposure of 1, to keep things simple; we will discuss more details on the exposure in the following subsection. <!-- %We start with looking at the linear regression model from a different angle. The linear regression formulated in (\ref{simple.linear.reg}\\\\) and  (\ref{simple.linear.reg.ft2}), when combined,  suggests an alternative description of the model --> <!-- %\begin{equation} --> <!-- %\label{ } --> <!-- %y_i= \E(y_i|\mathbf{ x}_i)+\epsilon_i --> <!-- %\end{equation} with $\E(y_i|\mathbf{ x}_i)=\mathbf{ x}^{\prime}_i\beta$, where $\beta=(\beta_0, \beta_1, \ldots, \beta_k)^{\prime}$. This expression tells that the response variable is the mean response function with the error term added.  --> As done before, we describe the Poisson regression through its mean function. For this we first denote <span class="math inline">\(\mu_i\)</span> to be the expected loss count of the <span class="math inline">\(i\)</span>th policyholder under the Poisson specification (1): <span class="math display">\[\begin{equation}
\mu_i=\mathrm{E~}{(y_i|\mathbf{ x}_i)}, \qquad y_i \sim Pois(\mu_i), \, i=1, \ldots, n. - (12)
\end{equation}\]</span> The condition inside the expectation operation in (12) indicates that the loss frequency <span class="math inline">\(\mu_i\)</span> is the model output responding to the given set of risk factors or explanatory variables. In principle the conditional mean <span class="math inline">\(\mathrm{E~}{(y_i|\mathbf{ x}_i)}\)</span> in (12) can take different forms depending on how we specify the relationship between <span class="math inline">\(\mathbf{ x}\)</span> and <span class="math inline">\(y\)</span>. The standard choice for the Poisson regression is to adopt the exponential function, as we mentioned previously, so that <span class="math display">\[\begin{equation}
\mu_i=\mathrm{E~}{(y_i|\mathbf{ x}_i)}=e^{\mathbf{ x}^{\prime}_i\beta}, \qquad y_i \sim Pois(\mu_i), \, i=1, \ldots, n. - (13)
\end{equation}\]</span> Here <span class="math inline">\(\beta=(\beta_0, \ldots, \beta_k)^{\prime}\)</span> is the vector of coefficients so that <span class="math inline">\(\mathbf{ x}^{\prime}_i\beta=\beta_0+\beta_1x_{i1} +\ldots+\beta_k x_{ik}\)</span>. The exponential function in (13) ensures that <span class="math inline">\(\mu_i &gt;0\)</span> for any set of rating factors <span class="math inline">\(\mathbf{ x}_i\)</span>. Often (13) is rewritten as a log linear form <span class="math display">\[\begin{equation}
\log \mu_i=\log \mathrm{E~}{(y_i|\mathbf{ x}_i)}=\mathbf{ x}^{\prime}_i\beta, \qquad y_i \sim Pois(\mu_i), \, i=1, \ldots, n - (14)
\end{equation}\]</span> to reveal the relationship when the right side is set as the linear form, <span class="math inline">\(\mathbf{ x}^{\prime}_i\beta\)</span>. Again, we see that the mapping works well as both sides of (14), <span class="math inline">\(\log \mu_i\)</span> and <span class="math inline">\(\mathbf{ x}_i\beta\)</span>, can now cover the entire real values. This is the formulation of the Poisson regression, assuming that all policyholders have the same unit period of exposure. When the exposures differ among the policyholders, however, as is the case in most practical cases, we need to revise this formulation by adding exposure component as an additional term in (14).</p>
<!-- %=================== -->
</div>
<div id="incorporating-exposure" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Incorporating exposure</h3>
<!-- %=================== -->
<p><strong>Concept of exposure</strong><br />
In order to determine the size of potential losses in any type of insurance, one must always know the corresponding exposure. The concept of exposure is an extremely important ingredient in insurance pricing, though we usually take it for granted. For example, when we say the expected claim frequency of a health insurance policy is 0.2, it does not mean much without the specification of the exposure such as, in this case, per month or per year. In fact, all premiums and losses need the exposure precisely specified and must be quoted accordingly; otherwise all subsequent statistical analyses and predictions will be distorted.</p>
<p>In the previous section we assumed the same unit of exposure across all policyholders, but this is hardly realistic in practice. In health insurance, for example, two different policyholders with different lengths of insurance coverage (e.g., 3 months and 12 months, respectively) could have recorded the same number of claim counts. As the expected number of claim counts would be proportional to the length of coverage, we should not treat these two policyholders’ loss experiences identically in the modelling process. This motivates the need of the concept of <em>exposure</em> in the Poisson regression.</p>
<p>The Poisson distribution in (1) is parametrised via its mean. To understand the exposure, we alternatively parametrize the Poisson pmf in terms of the <em>rate</em> parameter <span class="math inline">\(\lambda\)</span>, based on the definition of the Poisson process: <span class="math display">\[\begin{equation}
\Pr(Y=y)=\frac{(\lambda t)^y e^{-\lambda t}}{y!},\qquad y=0,1,2, \ldots - (15)
\end{equation}\]</span> with <span class="math inline">\(\mathrm{E~}{(Y)}=\mathrm{Var~}{(Y)}=\lambda t\)</span>. Here <span class="math inline">\(\lambda\)</span> is known as the rate or intensity per unit period of the Poisson process and <span class="math inline">\(t\)</span> represents the length of time or <em>exposure</em>, a known constant value. For given <span class="math inline">\(\lambda\)</span> the Poisson distribution (15) produces a larger expected loss count as the exposure <span class="math inline">\(t\)</span> gets larger. Clearly, (15) reduces to (1) when <span class="math inline">\(t=1\)</span>, which means that the mean and the rate become the same for the unit exposure, the case we considered in the previous subsection.</p>
<p>In principle the exposure does not need to be measured in units of time and may represent different things depending the problem at hand. For example,</p>
<ol style="list-style-type: decimal">
<li><p>In health insurance, the rate may be the occurrence of a specific disease per 1,000 people and the exposure is the number of people considered in the unit of 1,000.</p></li>
<li><p>In auto insurance, the rate may be the number of accidents per year of a driver and the exposure is the length of the observed period for the driver in the unit of year.</p></li>
<li><p>For workers compensation, the rate may be the probability of injury in the course of employment per dollar and the exposure is the payroll amount in dollar.</p></li>
<li><p>In marketing, the rate may be the number of customers who enter a store per hour and the exposure is the number of hours observed.</p></li>
<li><p>In civil engineering, the rate may be the number of major cracks on the paved road per 10 kms and the exposure is the length of road considered in the unit of 10 kms.</p></li>
</ol>
<!-- %  \item In biology, the rate may be  the number of a specific type of bacteria found per 1 cm$^3$ of sea water and the exposure is the volume of sea water considered in the unit of cubic centimeter.  -->
<ol start="6" style="list-style-type: decimal">
<li>In credit risk modelling, the rate may be the number of default events per 1000 firms and the exposure is the number of firms under consideration in the unit of 1,000.</li>
</ol>
<p>Actuaries may be able to use different exposure bases for a given insurable loss. For example, in auto insurance, both the number of kilometres driven and the number of months coved by insurance can be used as exposure bases. Here the former is more accurate and useful in modelling the losses from car accidents, but more difficult to measure and manage for insurers. Thus, a good exposure base may not be the theoretically best one due to various practical constraints. As a rule, an exposure base must be easy to determine, accurately measurable, legally and socially acceptable, and free from potential manipulation by policyholders.</p>
<p><strong>Incorporating exposure in Poisson regression</strong><br />
As exposures affect the Poisson mean, constructing Poisson regressions requires us to carefully separate the rate and exposure in the modelling process. Focusing on the insurance context, let us denote the rate of the loss event of the <span class="math inline">\(i\)</span>th policyholder by <span class="math inline">\(\lambda_i\)</span>, the known exposure (the length of coverage) by <span class="math inline">\(m_i\)</span> and the expected loss count under the given exposure by <span class="math inline">\(\mu_i\)</span>. Then the Poisson regression formulation in (13) and (14) should be revised in light of (15) as <span class="math display">\[\begin{equation}
\mu_i=\mathrm{E~}{(y_i|\mathbf{ x}_i)}=m_i \,\lambda_i=m_i \, e^{\mathbf{ x}^{\prime}_i\beta}, \qquad y_i \sim Pois(\mu_i), \, i=1, \ldots, n, - (16)
\end{equation}\]</span> which gives <span class="math display">\[\begin{equation}
\log \mu_i=\log m_i+\mathbf{ x}^{\prime}_i\beta, \qquad y_i \sim Pois(\mu_i), \, i=1, \ldots,  - (17)
\end{equation}\]</span> Adding <span class="math inline">\(\log m_i\)</span> in (17) does not pose a problem in fitting as we can always specify this as an extra explanatory variable, as it is a known constant, and fix its coefficient to 1. In the literature the log of exposure, <span class="math inline">\(\log m_i\)</span>, is commonly called the <strong>offset</strong>.</p>
<!-- %=================== -->
</div>
<div id="exercises" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Exercises</h3>
<!-- %=================== -->
<ol style="list-style-type: decimal">
<li><p>Regarding Table 8.1 answer the followings.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Verify the mean values in the table.</p></li>
<li><p>Verify the number in Equation (2).</p></li>
<li><p>Produce the fitted Poisson counts for each smoking status in the table.</p></li>
</ol></li>
<li><p>In the Poisson regression formulation (12), consider using <span class="math inline">\(\mu_i=\mathrm{E~}{(y_i|\mathbf{ x}_i)}=({\mathbf{ x}^{\prime}_i\beta})^2\)</span>, for <span class="math inline">\(i=1, \ldots, n\)</span>, instead of the exponential function What potential issue would you have?</p></li>
<li><p>Verify Equation (26) by differentiating the log-likelihood (23).</p></li>
</ol>
<!-- %=================== -->
</div>
</div>
<div id="categorical-variables-and-multiplicative-tariff" class="section level2">
<h2><span class="header-section-number">2.3</span> Categorical variables and multiplicative tariff</h2>
<!-- %=================== -->
<p>In this section you will learn:</p>
<ul>
<li><p>The multiplicative tariff model when the rating factors are categorical.</p></li>
<li><p>How to construct the Poisson regression model based on the multiplicative tariff structure.</p></li>
</ul>
<!-- %=================== -->
<div id="rating-factors-and-tariff" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Rating factors and tariff</h3>
<!-- %=================== -->
<p>In practice most rating factors in insurance are <em>categorical variables</em>, meaning that they take one of the pre-determined number of possible values. Examples of categorical variables include sex, type of cars, the driver’s region of residence and occupation. Continuous variables, such as age or auto mileage, can also be grouped by bands and treated as categorical variables. Thus we can imagine that, with a small number of rating factors, there will be many policyholders falling into the same risk class, charged with the same premium. For the remaining of this chapter we assume that all rating factors are categorical variables.</p>
<p>To illustrate how categorical variables are used in the pricing process, we consider a hypothetical auto insurance with only two rating factors:</p>
<ul>
<li>Type of vehicle: Type A (personally owned) and B (owned by corporations). We use index <span class="math inline">\(j=1\)</span> and <span class="math inline">\(2\)</span> to respectively represent each level of this rating factor.<br />
</li>
<li>Age band of the driver: Young (age <span class="math inline">\(&lt;\)</span> 25), middle (25 <span class="math inline">\(\le\)</span> age <span class="math inline">\(&lt;\)</span> 60) and old age (age <span class="math inline">\(\ge\)</span> 60). We use index <span class="math inline">\(k=1, 2\)</span> and <span class="math inline">\(3\)</span>, respectively, for this rating factor.</li>
</ul>
<!-- %  \item  -->
<p>From this classification rule, we may create an organized table or list, such as the one shown in Table 8.2, collected from all policyholders. Clearly there are <span class="math inline">\(2 \times 3=6\)</span> different risk classes in total. Each row of the table shows a combination of different risk characteristics of individual policyholders. Our goal is to compute six different premiums for each of these combinations. Once the premium for each row has been determined using the given exposure and claim counts, the insurer can replace the last two columns in Table 8.2 with a single column containing the computed premiums. This new table then can serve as a manual to determine the premium for a new policyholder given the rating factors during the underwriting process. In non-life insurance, a table (or a set of tables) or list that contains each set of rating factors and the associated premium is referred to as a <em>tariff</em>. Each unique combination of the rating factors in a tariff is called a <em>tariff cell</em>; thus, in Table 8.2 the number of tariff cells is six, same as the number of risk classes.</p>
<p><span class="math display">\[\begin{matrix}
\begin{array}{ccrrc}
 \hline
\text{Rating} &amp;\text{factors}  &amp;   \text{Exposure} &amp; \text{Claim count} \\
\text{Type }(j) &amp; \text{Age }(k) &amp;  \text{in year} &amp; \text{observed}\\
\hline \hline
j=1 &amp; k=1 &amp;  89.1 &amp; 9\\
1 &amp; 2   &amp; 208.5&amp; 8\\
1 &amp; 3  &amp; 155.2 &amp; 6  \\
2  &amp; 1  &amp; 19.3 &amp; 1 \\
2  &amp; 2  &amp; 360.4 &amp; 13 \\
2   &amp; 3  &amp; 276.7 &amp; 6 \\ \hline
\end{array}
\end{matrix}\]</span></p>
<p>[Table 8.2] : Loss record of the illustrative auto insurer</p>
<p>Let us now look at the loss information in Table 8.2 more closely. The exposure in each row represents the sum of the length of insurance coverages, or in-force times, in the unit of year, of all the policyholders in that tariff cell. Similarly the claim counts in each row is the number of claims at each cell. Naturally the exposures and claim counts vary due to the different number of drivers across the cells, as well as different in-force time periods among the drivers within each cell.</p>
<p>In light of the Poisson regression framework, we denote the exposure and claim count of cell <span class="math inline">\((j,k)\)</span> as <span class="math inline">\(m_{jk}\)</span> and <span class="math inline">\(y_{jk}\)</span>, respectively, and define the claim count per unit exposure as <span class="math display">\[\begin{equation}
\label{z.jk}\nonumber
z_{jk}= \frac{y_{jk}}{ m_{jk}}, \qquad j=1,2;\, k=1, 2,3.
\end{equation}\]</span> For example, <span class="math inline">\(z_{12}=8/208.5=0.03837\)</span>, meaning that a policyholder in tariff cell (1,2) would have 0.03837 accidents if insured for a full year on average. The set of <span class="math inline">\(z_{ij}\)</span> values then corresponds to the rate parameter in the Poisson distribution (15) as they are the event occurrence rates per unit exposure. That is, we have <span class="math inline">\(z_{jk}=\hat{\lambda}_{jk}\)</span> where <span class="math inline">\({\lambda}_{jk}\)</span> is the Poisson rate parameter. Producing <span class="math inline">\(z_{ij}\)</span> values however does not do much beyond comparing the average loss frequencies across risk classes. To fully exploit the dataset, we will construct a pricing model from Table 8.2 using the Poisson regression, for the remaining part of the chapter.</p>
<p>We comment that actual loss records used by insurers typically include much more risk factors, in which case the number of cells grows exponentially. The tariff would then consist of a set of tables, instead of one, separated by some of the basic rating factors, such as sex or territory.</p>
<!-- %=================== -->
</div>
</div>
<div id="multiplicative-tariff-model" class="section level2">
<h2><span class="header-section-number">2.4</span> Multiplicative tariff model</h2>
<!-- %=================== -->
<!-- %\noindent\textbf{Concept of tariff}\\ -->
<p>In this subsection, we introduce the multiplicative tariff model, a popular pricing structure that can be naturally used within the Poisson regression framework. The developments here is based on Table 8.2. Recall that the loss count of a policyholder is described by the Poisson regression model with rate <span class="math inline">\(\lambda\)</span> and the exposure <span class="math inline">\(m\)</span>, so that the expected loss count becomes <span class="math inline">\(m\lambda\)</span>. As <span class="math inline">\(m\)</span> is a known constant, we are essentially concerned with modelling <span class="math inline">\(\lambda\)</span>, so that it responds to the change in the rating factors. Among other possible functional forms, we commonly choose the multiplicative<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> relation to model the Poisson rate <span class="math inline">\(\lambda_{jk}\)</span> for rating factor (<span class="math inline">\(j,k\)</span>): <span class="math display">\[\begin{equation}
\lambda_{jk}= f_0 \times f_{1j} \times f_{2k}, \qquad j=1,2;\, k=1, 2,3. - (18)
\end{equation}\]</span></p>
<p>Here <span class="math inline">\(\{ f_{1j}, j=1,2\}\)</span> are the parameters associated with the two levels in the first rating factor, car type, and <span class="math inline">\(\{ f_{2k}, k=1,2,3\}\)</span> associated with the three levels in the age band, the second rating factor. For instance, the Poisson rate for a mid-aged policyholder with a Type B vehicle is given by <span class="math inline">\(\lambda_{22}=f_0 \times f_{12} \times f_{22}\)</span>. The first term <span class="math inline">\(f_0\)</span> is some base value to be discussed shortly. Thus these six parameters are understood as numerical representations of the levels within each rating factor, and are to be estimated from the dataset.</p>
<p>The multiplicative form (18) is easy to understand and use, because it clearly shows how the expected loss count (per unit exposure) changes as each rating factor varies. For example, if <span class="math inline">\(f_{11}=1\)</span> and <span class="math inline">\(f_{12}=1.2\)</span>, then the expected loss count of a policyholder with a vehicle of type B would be 20<span class="math inline">\(\%\)</span> larger than type A, when the other factors are the same. In non-life insurance, the parameters <span class="math inline">\(f_{1j}\)</span> and <span class="math inline">\(f_{2k}\)</span> are known as <em>relativities</em> as they determine how much expected loss should change relative to the base value <span class="math inline">\(f_0\)</span>. The idea of relativity is quite convenient in practice, as we can decide the premium for a policyholder by simply multiplying a series of corresponding relativities to the base value. <!-- % For example, suppose there are $p$ different risk factors, each of which has 3 levels. Then the expected loss frequency of a specific policyholder whose levels are given as, say,  $(2,1,3,3,2)$ for each risk factor respectively, is simply $\lambda=f_0 \, f_{12}\, f_{21}\, f_{33}\, f_{43}\, f_{52}$.  --> Dropping an existing rating factor or adding a new one is also transparent with this multiplicative structure. In addition, the insurer may easily adjust the overall premium for all policyholders by controlling the base value <span class="math inline">\(f_0\)</span> without changing individual relativities. However, by adopting the multiplicative form, we implicitly assume that there is no serious interaction among the risk factors.</p>
<p>When the multiplicative form is used we need to address an identification issue. That is, for any <span class="math inline">\(c&gt;0\)</span>, we can write <span class="math display">\[\begin{equation}
\lambda_{jk}= f_0 \times \frac{f_{1j}}{c} \times c\,f_{2k}. 
\end{equation}\]</span> By comparing with (18), we see that the identical rate parameter <span class="math inline">\(\lambda_{jk}\)</span> can be obtained for very different individual relativities. This over-parametrization, meaning that many different sets of parameters arrive at the identical model, obviously calls for some restriction on <span class="math inline">\(f_{1j}\)</span> and <span class="math inline">\(f_{2k}\)</span>. The standard practice is to make one relativity in each rating factor equal to one. This can be made arbitrarily, so we will assume that <span class="math inline">\(f_{11}=1\)</span> and <span class="math inline">\(f_{21}=1\)</span> for our purpose. This way all other relativities are uniquely determined. The tariff cell <span class="math inline">\((j,k)=(1,1)\)</span> is then called the <em>base tariff cell</em>, where the rate simply becomes <span class="math inline">\(\lambda_{11}=f_0\)</span>, corresponding to the base value according to (18). Thus the base value <span class="math inline">\(f_0\)</span> is generally interpreted as the Poisson rate of the base tariff cell.</p>
<p>Again, (18) is log-transformed and rewritten as <span class="math display">\[\begin{equation}
\log \lambda_{jk}= \log f_0 + \log f_{1j} + \log f_{2k}, - (19) 
\end{equation}\]</span> as it is easier to work with in estimating process, similar to (14). This log linear form makes the log relativities of the base level in each rating factor equal to zero, i.e., <span class="math inline">\(\log f_{11}=\log f_{21}=0\)</span>, and leads to the following alternative, more explicit expression for (19): <span class="math display">\[\begin{equation}
\log \lambda=\begin{cases}
      \log f_0 + \quad 0 \quad \,\,+ \quad 0 \quad \,\,&amp; \text{for a policy in cell $(1,1)$}, \\
            \log f_0+ \quad 0 \quad \,\,+\log f_{22}&amp; \text{for a policy in cell $(1,2)$}, \\
                  \log f_0+ \quad 0 \quad \,\,+\log f_{23}&amp; \text{for a policy in cell $(1,3)$}, \\
                        \log f_0+\log f_{12}+ \quad 0 \quad \,\,&amp; \text{for a policy in cell $(2,1)$}, \\
                              \log f_0+\log f_{12}+\log f_{22}&amp; \text{for a policy in cell $(2,2)$}, \\
                                    \log f_0+\log f_{12}+\log f_{23}&amp; \text{for a policy in cell $(2,3)$}. \\
\end{cases} - (20)
\end{equation}\]</span> This clearly shows that the Poisson rate parameter <span class="math inline">\(\lambda\)</span> varies across different tariff cells, with the same log linear form used in the Poisson regression framework. In fact the reader may see that (20) is an extended version of the early expression (6) with multiple risk factors and that the log relativities now play the role of <span class="math inline">\(\beta_i\)</span> parameters. Therefore all the relativities can be readily estimated via fitting a Poisson regression with a suitably chosen set of indicator variables.</p>
<!-- % -->
<!-- %The log-linear model (\ref{log-linear.tariff}) resembles the two-way analysis of variance (ANOVA) in Statistics, which studies how two different factors or treatments affect the mean outcome of quantity of interest. Thus we may adopt the standard statistical techniques for our tariff analysis.  -->
<!-- %One may also consider the additive form, i.e., $\lambda_{ij}= f_0 + f_{1i} + f_{2j}$, but the multiplicative version is known to be more appropriate for actual applications. By taking logarithm on (\ref{multi.tariff.1}) we have the log-linear form -->
<!-- %\begin{equation} -->
<!-- %\label{multi.tariff.4} -->
<!-- %\log \lambda_{ij}= \log f_0 + \log f_{1i} + \log f_{2j}, \qquad i=1,2; j=1, \ldots, 5 -->
<!-- %\end{equation} -->
<!-- %=================== -->
<div id="poisson-regression-for-multiplicative-tariff" class="section level3">
<h3><span class="header-section-number">2.4.1</span> Poisson regression for multiplicative tariff</h3>
<!-- %=================== -->
<p><strong>Indicator variables for tariff cells</strong><br />
We now explain how the relativities can be incorporated in the Poisson regression. As seen early in this chapter we use indicator variables to deal with categorial variables. For our illustrative auto insurer, therefore, we define an indicator variable for the first rating factor as <span class="math display">\[\begin{equation}
x_1=
\begin{cases}
      1 &amp; \text{ for vehicle type B}, \\
      0 &amp; \text{ otherwise}.
\end{cases}
\end{equation}\]</span> For the second rating factor, we employ two indicator variables for the age band, that is, <span class="math display">\[\begin{equation}
x_2=
\begin{cases}
     1 &amp; \text{for age band 2}, \\
     0 &amp; \text{otherwise}.
\end{cases}
\end{equation}\]</span> and <span class="math display">\[\begin{equation}
x_3=
\begin{cases}
     1 &amp; \text{for age band 3}, \\
     0 &amp; \text{otherwise}.
\end{cases}
\end{equation}\]</span> The triple <span class="math inline">\((x_1, x_2, x_3)\)</span> then can effectively and uniquely determine each risk class. By observing that the indicator variables associated with Type A and Age band 1 are omitted, we see that tariff cell <span class="math inline">\((j,k)=(1,1)\)</span> plays the role of the base cell. We emphasize that our choice of the three indicator variables above has been carefully made so that it is consistent with the choice of the base levels in the multiplicative tariff model in the previous subsection (i.e., <span class="math inline">\(f_{11}=1\)</span> and <span class="math inline">\(f_{21}=1\)</span>).<br />
<!-- % --> <!-- % In addition, there is a one-to-one mapping between the tariff cell index $(j,k)$ and the triple $(x_1, x_2, x_3)$.  --> <!-- %For example, cell $(j,k)=(2,2)$ corresponds to $(1, 1, 0)$, and the base cell $(j,k)=(1,1)$ corresponds to $(0, 0, 0)$.  --> <!-- % --></p>
<p>With the proposed indicator variables we can rewrite the log rate (19) as <span class="math display">\[\begin{equation}
\log \lambda_{}= \log f_0+ \log f_{12}  \times x_1 + \log f_{22} \times x_2 +\log f_{23} \times x_3, - (21)
\end{equation} \]</span> which is identical to (20) when each triple value is actually applied. For example, we can verify that the base tariff cell <span class="math inline">\((j,k)=(1,1)\)</span> corresponds to <span class="math inline">\((x_1, x_2,x_3)=(0, 0, 0)\)</span>, and in turn produces <span class="math inline">\(\log \lambda=\log f_0\)</span> or <span class="math inline">\(\lambda= f_0\)</span> in (21) as required. <!-- %Also note that we do not need to include $f_{11}$ and $f_{21}$ in (\ref{log-linear.tariff.3}) as $\log f_{11}=\log f_{21}=0$ by construction. If we reverse the binary switch for $x_i$ in  (\ref{ind.x1}) -- (\ref{ind.x3}) or select different coefficients in (\ref{log-linear.tariff.3}), we will lose this internal consistency; --> <!-- % --> <!-- %%For example, for a policyholder at cell $(j,k)=(2,2)$ we have $(x_1, x_2,x_3)=(1,1,0)$ to yield, from (\ref{log-linear.tariff.3}),  $\log \lambda_{22}=\log f_0+\log f_{22}$, and for the  base cell $(j,k)=(1,1)$ corresponding to $(x_1, x_2,x_3)=(0, 0, 0)$, we obtain $\log \lambda_{11}=\log f_0$. --> <!-- %the base cell produces a vector of zeros, $(x_1, x_2,x_3)=(0, 0, 0)$. This way, the log intensity for the base cell yields $\lambda_{11}=f_0$ as required. Also note that we do not need to include $f_{11}$ and $f_{21}$ in (\ref{log-linear.tariff.3}) as $\log f_{11}=\log f_{21}=0$ by construction. If we reverse the binary switch for $x_i$ in  (\ref{ind.x1}) -- (\ref{ind.x3}) or select different coefficients in (\ref{log-linear.tariff.3}), we will lose this internal consistency; --> <!-- %% so that it is set 1 for vehicle type A and 0 for type B, then the base cell $(j,k)=(1,1)$ produces $(x_1, x_2,x_3)=(1, 0, 0)$, which in turn gives $\log \lambda_{11}=\log f_0+ \log f_{12}$ or $\lambda_{11}=f_0\,f_{12}$ from (\ref{log-linear.tariff.3}). This is not acceptable as $f_0\,f_{12}$ describes the price relativity of cell $(2, 1)$ instead of $(1, 1)$, violating our requirement of $\lambda_{11}=f_0$.  --> <!-- %in an exercise question, the reader is invited to check this.  --></p>
<p><strong>Poisson regression for the tariff model}</strong><br />
Under this specification, let us consider <span class="math inline">\(n\)</span> policyholders in the portfolio with the <span class="math inline">\(i\)</span>th policyholder’s risk characteristic given by a vector of explanatory variables <span class="math inline">\(\mathbf{ x}_i=(x_{i1}, x_{i2},x_{i3})^{\prime}\)</span>, for <span class="math inline">\(i=1, \ldots, n\)</span>. We then recognize (21) as <span class="math display">\[\begin{equation}
\log \lambda_{i}= \beta_0+ \beta_1 \, x_{i1} + \beta_{2} \, x_{i2} +\beta_3  \, x_{i3}=\mathbf{ x}^{\prime}_i\beta, \qquad i=1, \ldots, n,
\end{equation}\]</span> where <span class="math inline">\(\beta_0, \ldots, \beta_3\)</span> can be mapped to the corresponding log relativities in (21). This is exactly the same setup as in (17) except for the exposure component. Therefore, by incorporating the exposure in each risk class, the Poisson regression model for this multiplicative tariff model finally becomes <span class="math display">\[\begin{equation}
\log \mu_i=\log \lambda_{i}+\log m_i= \log m_i+ \beta_0+ \beta_1 \, x_{i1} + \beta_{2} \, x_{i2} +\beta_3  \, x_{i3}=\log m_i+\mathbf{ x}^{\prime}_i\beta, 
\end{equation}\]</span> for <span class="math inline">\(i=1, \ldots, n\)</span>. As a result, the relativities are given by <span class="math display">\[\begin{equation}
{f}_0=e^{\beta_0}, \quad {f}_{12}=e^{\beta_1}, \quad {f}_{22}=e^{\beta_2} \quad \text{and}\quad {f}_{23}=e^{\beta_3}, - (22)
\end{equation}\]</span> with <span class="math inline">\(f_{11}=1\)</span> and <span class="math inline">\(f_{21}=1\)</span> from the original construction. For the actual dataset, <span class="math inline">\(\beta_i\)</span>, <span class="math inline">\(i=0,1, 2, 3\)</span>, is replaced with the mle <span class="math inline">\(b_i\)</span> using the method in the technical supplement at the end of this chapter (Section 1.6).<br />
<!-- % --> <!-- %Using the mle, we obtain the estimated parameters $\mathbf{ b}=(b_0, \ldots, b_3)^{\prime}$ and, which in turn, gives the following estimated relativities --> <!-- %\begin{equation} --> <!-- %\label{ } --> <!-- %{f}_0=e^{b_0}, \quad {f}_{12}=e^{b_1}, \quad {f}_{22}=e^{b_2} \quad \text{and}\quad {f}_{23}=e^{b_3}, --> <!-- %\end{equation} with $f_{11}=1$ and $f_{21}=1$ from the original construction.  --> <!-- % --> <!-- %Finally, in applying this Poisson regression model to model to the data in Table \ref{tab.tariff.1},  --> <!-- %one should be aware that the mle in Section \ref{mle.Pois.reg} cannot be directly used. This is because Table \ref{tab.tariff.1} does not provides the loss counts or exposures of individual policyholders. In other words, $y_i$ and $m_i$, needed for the mle calculation, are unavailable from the table.   --> <!-- %  --> <!-- % $f_{0}$, $f_{1j}$ and $f_{2k}$ in the same way as we did in (\ref{mean.ft.Pois6}) and (\ref{mean.ft.Pois7}). In Table \ref{tab.tariff.2} we present the mapping between $\beta_i$ coefficients and the price relatives, keeping the same list form as Table \ref{tab.tariff.1}. All columns except for the first is indexed with $i$, giving us a complete specification for our Poisson regression. --> <!-- % --> <!-- %\begin{table}[htp] --> <!-- %\caption{Tariff parametrization of an illustrative auto insurer} --> <!-- %\begin{center} --> <!-- %\begin{tabular}{cccccc} --> <!-- % \hline --> <!-- %{Rating factors } &  Risk class & Covariates & Price relativity & Exposure & Claim count \\ --> <!-- %$(j,k)$ & $i$ & $(x_{i1}, x_{i2},x_{i3})$ & $\lambda_i=e^{\mathbf{ x}_i\beta}$&  $m_i$ & $y_i$\\ --> <!-- %\hline \hline --> <!-- %$(1,1)$ &  1 & $(0,0,0)$ & $\lambda_1=f_0f_{11}f_{21}$ & 89.1 & 9\\ --> <!-- %$(1,2)$ &2  & $(0,1,0)$ & $\lambda_2=f_0f_{11}f_{22}$ & 208.5& 8\\ --> <!-- %$(1, 3)$ & 3 &$(0,0,1)$ & $\lambda_3=f_0f_{11}f_{23}$ & 155.2 & 6  \\ --> <!-- %$(2 , 1)$ & 4 & $(1,0,0)$ & $\lambda_4=f_0f_{12}f_{21}$ & 19.3 & 1 \\ --> <!-- %$(2 , 2)$ & 5 & $(1,1,0)$ & $\lambda_5=f_0f_{12}f_{22}$& 360.4 & 13 \\ --> <!-- %$(2 , 3)$ & 6 & $(1,0,1)$ & $\lambda_6=f_0f_{12}f_{23}$ & 276.7 & 6 \\ \hline --> <!-- %\end{tabular} --> <!-- %\end{center} --> <!-- %\label{tab.tariff.2} --> <!-- %\end{table}% --> <!-- %  --> <!-- %\begin{table}[htp] --> <!-- %\caption{Tariff parametrization of an illustrative auto insurer} --> <!-- %\begin{center} --> <!-- %\begin{tabular}{rrccrcrc} --> <!-- % \hline --> <!-- % \multicolumn{2}{c}{Rating factors } & \multicolumn{2}{c}{Relatives} & Risk class ($i$)& $(x_{i1}, x_{i2},x_{i3})$ &Exposure & Claim count \\ --> <!-- % \cline{1-2}  \cline{3-4}  --> <!-- %Type ($j$) &  Age ($k$) & Type ($j$) &  Age ($k$) &(Tariff cell) & & in year & observed\\ --> <!-- %\hline \hline --> <!-- %$j=$1 & $k=$1 & $f_{11}$ & $f_{21}$& 1 & $(0,0,0)$ &89.1 & 9\\ --> <!-- %1 & 2 &2  & 208.5& 8\\ --> <!-- %1 & 3 & 3 & 155.2 & 6  \\ --> <!-- %2  & 1 & 4 & 19.3 & 1 \\ --> <!-- %2  & 2 & 5 & 360.4 & 13 \\ --> <!-- %2   & 3 & 6 & 276.7 & 6 \\ \hline --> <!-- %\end{tabular} --> <!-- %\end{center} --> <!-- %\label{tab.tariff.2} --> <!-- %\end{table}% --> <!-- %We can generalise this to a case where there many rating factors. Assume that there are $p$ predictors, $(x_1, \ldots ,x_p)$, after accounting for all relevant indicator variables. Then  --></p>
<!-- %=================== -->
</div>
<div id="numerical-examples" class="section level3">
<h3><span class="header-section-number">2.4.2</span> Numerical examples</h3>
<!-- %=================== -->
<p>We present two numerical examples of the Poisson regression. In the first example we construct a Poisson regression model from Table 8.2, which is a dataset of a hypothetical auto insurer. The second example uses an actual industry dataset with more risk factors. As our purpose is to show how the Poisson regression model can be used under a given classification rule, we are not concerned with the quality of the Poisson model fit in this chapter.</p>
<p><strong>Example 1: Poisson regression for the illustrative auto insurer</strong><br />
In the last few subsections we considered a dataset of a hypothetical auto insurer with two risk factors, as given in Table 8.2. We now apply the Poisson regression model to this dataset. As done before, we have set <span class="math inline">\((j,k)=(1,1)\)</span> as the base tariff cell, so that <span class="math inline">\(f_{11}=f_{21}=1\)</span>. The result of the regression gives the coefficient estimates <span class="math inline">\((b_0, b_1,b_2,b_3)=(-2.3359, -0.3004, -0.7837, -1.0655 )\)</span>, which in turn produces the corresponding relativities <span class="math display">\[\begin{equation}
\label{relativity.eg1} \nonumber
{f}_0=0.0967, \quad {f}_{12}=  0.7405, \quad {f}_{22}=0.4567 \quad \text{and}\quad {f}_{23}=0.3445.
\end{equation}\]</span> from the relation given in (22). The R script and the output are given below:</p>
<div class="sourceCode"><pre class="sourceCode latex"><code class="sourceCode latex">&gt; mydat1&lt;- read.csv(&quot;eg1_v1a.csv&quot;)
&gt; mydat1
  Vtype Agebnd Expsr Claims
1     1      1  89.1      9
2     1      2 208.5      8
3     1      3 155.2      6
4     2      1  19.3      1
5     2      2 360.4     13
6     2      3 276.7      6
&gt; VtypeF &lt;- relevel(factor(Vtype), ref=&quot;1&quot;) # treat Vtype as factors with 1 as base.
&gt; AgebndF &lt;- relevel(factor(Agebnd), ref=&quot;1&quot;) # treat Age band as factors.
&gt; Pois_reg1 = glm(Claims ~ VtypeF + AgebndF,
                    data = mydat1, family = poisson(link = log), offset = log(Expsr) )
&gt; Pois_reg1

Coefficients:
(Intercept)      VtypeF2     AgebndF2     AgebndF3  
    -2.3359      -0.3004      -0.7837      -1.0655  

Degrees of Freedom: 5 Total (i.e. Null);  2 Residual
Null Deviance:      8.774 
Residual Deviance: 0.6514   AIC: 30.37</code></pre></div>
<!--  \begin{verbatim} -->
<!-- > mydat1<- read.csv("eg1_v1a.csv") -->
<!-- > mydat1 -->
<!--   Vtype Agebnd Expsr Claims -->
<!-- 1     1      1  89.1      9 -->
<!-- 2     1      2 208.5      8 -->
<!-- 3     1      3 155.2      6 -->
<!-- 4     2      1  19.3      1 -->
<!-- 5     2      2 360.4     13 -->
<!-- 6     2      3 276.7      6 -->
<!-- > VtypeF <- relevel(factor(Vtype), ref="1") # treat Vtype as factors with 1 as base. -->
<!-- > AgebndF <- relevel(factor(Agebnd), ref="1") # treat Age band as factors. -->
<!-- > Pois_reg1 = glm(Claims ~ VtypeF + AgebndF, -->
<!--                    data = mydat1, family = poisson(link = log), offset = log(Expsr) ) -->
<!-- > Pois_reg1 -->
<!-- Coefficients: -->
<!-- (Intercept)      VtypeF2     AgebndF2     AgebndF3   -->
<!--     -2.3359      -0.3004      -0.7837      -1.0655   -->
<!-- Degrees of Freedom: 5 Total (i.e. Null);  2 Residual -->
<!-- Null Deviance:     8.774  -->
<!-- Residual Deviance: 0.6514  AIC: 30.37 -->
<!-- \end{verbatim}   -->
<p><strong>Example 2: Poisson regression for Singapore insurance claims data</strong><br />
This actual data is a subset of the data used by <span class="citation">(<span class="citeproc-not-found" data-reference-id="frees2008hierarchical"><strong>???</strong></span>)</span>. The data is from the General Insurance Association of Singapore, an organisation consisting of non-life insurers in Singapore. The data contains the number of car accidents for <span class="math inline">\(n=7,483\)</span> auto insurance policies with several categorical explanatory variables and the exposure for each policy. The explanatory variables include four risk factors: the type of the vehicle insured (either automobile (A) or other (O), denoted by <span class="math inline">\(\verb&quot;Vtype&quot;\)</span>), the age of the vehicle in years (<span class="math inline">\(\verb&quot;Vage&quot;\)</span>), gender of the policyholder (<span class="math inline">\(\verb&quot;Sex&quot;\)</span>) and the age of the policyholder (in years, grouped into seven categories, denoted <span class="math inline">\(\verb&quot;Age&quot;\)</span>).<br />
Based on the data description, there are several things to remember before constructing a model (May need the table from the Jed’s pdf file). First, there are 3,842 policies with vehicle type A (automobile) and 3,641 policies with other vehicle types. However, age and sex information is available for the policies of vehicle type A only; the drivers of all other types of vehicles are recorded to be aged 21 or less with sex unspecified, except for one policy, indicating that no driver information has been collected for non-automobile vehicles. Second, type A vehicles are all classified as private vehicles and all the other types are not.</p>
<p>When we include these risk factors, we assume that all unspecified sex to be male. As the age information is only applicable to type A vehicles, we set the model accordingly. That is, we apply the age variable only to vehicles of type A. Also we used five vehicle age bands, simplifying the original seven bands, by combining vehicle ages 0,1 and 2; the combined band is marked as level 2<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> in the data file}. Thus our Poisson model has the following explicit form: <span class="math display">\[\begin{align*}
\log \mu_i= \mathbf{ x}^{\prime}_i\beta+&amp;\log m_i=\beta_0+\beta_1 I(Sex_i=M)+ \sum_{t=2}^6 \beta_t\, I(Vage_i=t+1) \\
&amp;+  \sum_{t=7}^{13} \beta_t \,I(Vtype_i=A)\times I(Age_i=t-7)+\log m_i.
\end{align*}\]</span></p>
<p>The fitting result is given in Table 8.3, for which we have several comments.</p>
<ul>
<li><p>The claim frequency is higher for male by 17.3%, when other rating factors are held fixed. However, this may have been affected by the fact that all unspecified sex has been assigned to male.</p></li>
<li><p>Regarding the vehicle age, the claim frequency gradually decreases as the vehicle gets old, when other rating factors are held fixed. The level starts from 2 for this variable but, again, the numbering is nominal and does not affect the numerical result.</p></li>
<li><p>The policyholder age variable only applies to type A (automobile) vehicle, and there is no policy in the first age band. We may speculate that younger drivers less than age 21 drive their parents’ cars rather than having their own because of high insurance premiums or related regulations. The missing relativity may be estimated by some interpolation or the professional judgement of the actuary. The claim frequency is the lowest for age band 3 and 4, but gets substantially higher for older age bands, a reasonable pattern seen in many auto insurance loss datasets.</p></li>
</ul>
<p>*We also note that there is no base level in the policyholder age variable, in the sense that no relativity is equal to 1. This is because the variable is only applicable to vehicle type A. This does not cause a problem numerically, but one may set the base relativity as follows if necessary for other purposes. Since there is no policy in age band 0, we consider band 1 as the base case. Specifically, we treat its relativity as a product of 0.918 and 1, where the former is the common relativity (that is, the common premium reduction) applied to all policies with vehicle type A and the latter is the base value for age band 1. Then the relativity of age band 2 can be seen as <span class="math inline">\(0.917=0.918 \times 0.999\)</span>, where 0.999 is understood as the relativity for age band 2. The remaining age bands can be treated similarly.</p>
<p><span class="math display">\[\begin{matrix}
\begin{array}{clcc}
\hline
\text{Rating factor} &amp; \text{Level} &amp; \text{Relativity in the tariff} &amp; \text{Note}\\ \hline\hline
\text{Base value}  &amp;  &amp; 0.167 &amp; f_0\\ \hline
\text{Sex} &amp; 1 (F) &amp; 1.000 &amp; \text{Base level}\\
 &amp; 2 (M) &amp; 1.173 &amp;\\\hline
 \text{Vehicle age} &amp; 2 (0-2\text{ yrs}) &amp; 1.000 &amp; \text{Base level}\\
  &amp; 3 (3-5\text{ yrs}) &amp; 0.843 \\
  &amp; 4 (6-10\text{ yrs}) &amp; 0.553 \\
  &amp; 5 (11-15\text{ yrs}) &amp; 0.269 \\
  &amp; 6 (16+\text{ yrs}) &amp; 0.189 &amp;\\\hline
  \text{Policyholder age} &amp; 0 (0-21) &amp; \text{N/A} &amp; \text{No policy} \\
  \text{(Only applicable to} &amp; 1 (22-25) &amp; 0.918 \\
 \text{vehicle type A)}  &amp; 2 (26-35) &amp; 0.917 \\
  &amp; 3 (36-45) &amp; 0.758 \\
  &amp; 4 (46-55) &amp; 0.632 \\
  &amp; 5 (56-65) &amp;  1.102\\
  &amp; 6 (65+) &amp; 1.179\\ \hline \hline
\end{array}
\end{matrix}\]</span> [Table 8.3] : Singapore insurance claims data</p>
<p>Let us try several examples based on Table 8.3. Suppose a male policyholder aged 40 who owns a 7-year-old vehicle of type A. The expected claim frequency for this policyholder is then given by <span class="math display">\[\begin{equation}
\lambda=0.167 \times 1.173 \times 0.553 \times 0.758 = 0.082.
\end{equation}\]</span> As another example consider a female policyholder aged 60 who owns a 3-year-old vehicle of type O. The expected claim frequency for this policyholder is <span class="math display">\[\begin{equation}
\lambda=0.167 \times 1 \times 0.843  = 0.141.
\end{equation}\]</span> Note that for this policy the age band variable is not used as the vehicle type is not A. The R script is given below.</p>
<!-- % -->
<!-- % -->
<!-- % -->
<div class="sourceCode"><pre class="sourceCode latex"><code class="sourceCode latex">mydat &lt;- read.csv(&quot;SingaporeAuto.csv&quot;,  quote = &quot;&quot;, header = TRUE)
attach(mydat)

# create vehicle type as factor
TypeA = 1 * (VehicleType == &quot;A&quot;)
table(VehicleType)
VtypeF &lt;- as.character(VehicleType)
VtypeF[VtypeF != &quot;A&quot;] &lt;- &quot;O&quot;
VtypeF = relevel(factor(VtypeF), ref=&quot;A&quot;)

# create gender as factor
Female = 1 * (SexInsured == &quot;F&quot; )
Sex = as.character(SexInsured)
Sex[Sex != &quot;F&quot;] &lt;- &quot;M&quot;
SexF = relevel(factor(Sex), ref = &quot;F&quot;)

# create driver age as factor
AgeCat = pmax(AgeCat - 1, 0)
AgeCatF = relevel(factor(AgeCat), ref = &quot;0&quot;)
table(AgeCatF) # No policy in the first age band

# create vehicle age as factor
VAgeCatF = relevel( factor(VAgeCat), ref = &quot;0&quot; )
VAgecat1 = factor(VAgecat1, labels = 
                    c(&quot;Vage0-2&quot;, &quot;Vage3-5&quot;, &quot;Vage6-10&quot;, &quot;Vage11-15&quot;, &quot;Vage15+&quot;) )
VAgecat1F = relevel( factor(VAgecat1), ref = &quot;Vage0-2&quot; )

# Poisson reg model
Pois_reg2 = glm(Clm_Count ~ SexF + TypeA:AgeCatF + VAgecat1F, 
                   offset = LNWEIGHT, poisson(link = log) )
summary(Pois_reg2) 

# compute relativities
exp(Pois_reg2<span class="ss">$coefficients)</span>

<span class="ss">detach(mydat)</span></code></pre></div>
<!-- % -->
<!-- %Note that the line for the interaction term of $I(Vtype=A)I(Age\,Band=0)$ has \verb"NA" values because there is no policy found in this category. Based on this output we may find the relativities for each risk factor, as shown in Table xxx. -->
<!-- % -->
<!-- %Our goal is to construct a Poisson regression model based on several risk factors.  -->
<!-- % -->
<!-- %=================== -->
</div>
</div>
<div id="further-reading-and-references" class="section level2">
<h2><span class="header-section-number">2.5</span> Further Reading and References</h2>
<!-- %=================== -->
<p>The Poisson regression is a special member of a more general regression model class known as the generalized linear model (glm). The glm develops a unified regression framework for datasets when the response valuables are continuous, binary or discrete. The classical linear regression model with normal error is also a member of the glm. There are many standard statistical texts dealing with the glm, including <span class="citation">(<span class="citeproc-not-found" data-reference-id="mccullagh1989generalized"><strong>???</strong></span>)</span>. More accessible texts are <span class="citation">(<span class="citeproc-not-found" data-reference-id="dobson2008introduction"><strong>???</strong></span>)</span>, <span class="citation">(<span class="citeproc-not-found" data-reference-id="agresti1996introduction"><strong>???</strong></span>)</span> and <span class="citation">(<span class="citeproc-not-found" data-reference-id="faraway2016extending"><strong>???</strong></span>)</span>. For actuarial and insurance applications of the glm see <span class="citation">(<span class="citeproc-not-found" data-reference-id="frees2009regression"><strong>???</strong></span>)</span>, <span class="citation">(<span class="citeproc-not-found" data-reference-id="de2008generalized"><strong>???</strong></span>)</span>. Also, <span class="citation">(<span class="citeproc-not-found" data-reference-id="ohlsson2010non"><strong>???</strong></span>)</span> discusses the glm in non-life insurance pricing context with tariff analyses.</p>
<!-- %=================== -->
</div>
<div id="S:mle.Pois.reg" class="section level2">
<h2><span class="header-section-number">2.6</span> Technical supplements – Estimating Poisson regression model</h2>
<!-- %=================== -->
<p><strong>Maximum likelihood estimation for individual data</strong><br />
In the Poisson regression the varying Poisson mean is determined by parameters <span class="math inline">\(\beta_i\)</span>’s, as shown in (17). In this subsection we use the maximum likelihood method to estimate these parameters. Again, we assume that there are <span class="math inline">\(n\)</span> policyholders and the <span class="math inline">\(i\)</span>th policyholder is characterized by <span class="math inline">\(\mathbf{ x}_i=(1, x_{i1}, \ldots, x_{ik})^{\prime}\)</span> with the observed loss count <span class="math inline">\(y_i\)</span>. Then, from (16) and (17), the log-likelihood function of vector <span class="math inline">\(\beta=(\beta_0, \dots, \beta_k)\)</span> is given by <span class="math display">\[\begin{align}
\nonumber \log L(\beta)    &amp;= l(\beta)=\sum^n_{i=1} \left( -\mu_i +y_i \, \log \mu_i -\log y_i! \right)  \\
    &amp;  = \sum^n_{i=1} \left( -m_i \exp(\mathbf{ x}^{\prime}_i\beta) +y_i \,(\log m_i+\mathbf{ x}^{\prime}_i\beta)  -\log y_i! \right) - (23)  
\end{align}\]</span> To obtain the mle of <span class="math inline">\(\beta=(\beta_0, \ldots, \beta_k)^{\prime}\)</span>, we differentiate<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> <span class="math inline">\(l(\beta)\)</span> with respect to vector <span class="math inline">\(\beta\)</span> and set it to zero: <span class="math display">\[\begin{equation}
\frac{\partial}{\partial \beta}l(\beta)\Bigg{|}_{\beta=\mathbf{ b}}=\sum^n_{i=1} \left(y_i -m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ b}) \right)\mathbf{ x}_i=\mathbf{ 0}. - (24)
\end{equation}\]</span></p>
<p>Numerically solving this equation system gives the mle of <span class="math inline">\(\beta\)</span>, denoted by <span class="math inline">\(\mathbf{ b}=(b_0, b_1, \ldots, b_k)^{\prime}\)</span>. Note that, as <span class="math inline">\(\mathbf{ x}_i=(1, x_{i1}, \ldots, x_{ik})^{\prime}\)</span> is a column vector, Equation (24) is a system of <span class="math inline">\(k+1\)</span> equations with both sides written as column vectors of size <span class="math inline">\(k+1\)</span>. If we denote <span class="math inline">\(\hat{\mu}_i=m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ b})\)</span>, we can rewrite (24) as <span class="math display">\[\begin{equation}
\sum^n_{i=1} \left(y_i -\hat{\mu}_i \right)\mathbf{ x}_i=\mathbf{ 0}.
\end{equation}\]</span> Since the solution <span class="math inline">\(\mathbf{ b}\)</span> satisfies this equation, it follows that the first among the array of <span class="math inline">\(k+1\)</span> equations, corresponding to the first constant element of <span class="math inline">\(\mathbf{ x}_i\)</span>, yields <span class="math display">\[\begin{equation}
\sum^n_{i=1}\left( y_i -\hat{\mu}_i \right)\times 1={ 0},
\end{equation}\]</span> which implies that we must have <span class="math display">\[\begin{equation}
n^{-1}\sum_{i=1}^n y_i =\bar{y}=n^{-1}\sum_{i=1}^n \hat{\mu}_i.
\end{equation}\]</span> This is an interesting property saying that the average of the individual losses, <span class="math inline">\(\bar{y}\)</span>, is same as the average of the estimated values. That is, the sample mean is preserved under the fitted Poisson regression model.</p>
<p><strong>Maximum likelihood estimation for grouped data</strong><br />
Sometimes the data is not available at the individual policy level. For example, Table 8.2 provides collective loss information for each risk class after grouping individual policies. When this is the case, <span class="math inline">\(y_i\)</span> and <span class="math inline">\(m_i\)</span>, the quantities needed for the mle calculation in (24), are unavailable for each <span class="math inline">\(i\)</span>. However this does not pose a problem as long as we have the total loss counts and total exposure for each risk class.</p>
<p>To elaborate, let us assume that there are <span class="math inline">\(K\)</span> different risk classes, and further that, in the <span class="math inline">\(k\)</span>th risk class, we have <span class="math inline">\(n_k\)</span> policies with the total exposure <span class="math inline">\(m_{(k)}\)</span> and the average loss count <span class="math inline">\(\bar{y}_{(k)}\)</span>, for <span class="math inline">\(k=1, \ldots, K\)</span>; the total loss count for the <span class="math inline">\(k\)</span>th risk class is then <span class="math inline">\(n_k\, \bar{y}_{(k)}\)</span>. We denote the set of indices of the policies belonging to the <span class="math inline">\(k\)</span>th class by <span class="math inline">\(C_k\)</span>. As all policies in a given risk class share the same risk characteristics, we may denote <span class="math inline">\(\mathbf{ x}_i=\mathbf{ x}_{(k)}\)</span> for all <span class="math inline">\(i \in C_k\)</span>. With this notation, we can rewrite (24) as <span class="math display">\[\begin{align}
\nonumber \sum^n_{i=1} \left(y_i -m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ b}) \right)\mathbf{ x}_i &amp;= \sum^K_{k=1}\Big{\{}\sum_{i \in C_k} \left(y_i -m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ b}) \right)\mathbf{ x}_i  \Big{\}} \\
\nonumber     &amp;  =\sum^K_{k=1}\Big{\{} \sum_{i \in C_k} \left(y_i -m_i \exp(\mathbf{ x}^{\prime}_{(k)} \mathbf{ b}) \right)\mathbf{ x}_{(k)}  \Big{\}} \\
\nonumber     &amp;  =\sum^K_{k=1}\Big{\{}  \Big(\sum_{i \in C_k}y_i -\sum_{i \in C_k}m_i \exp(\mathbf{ x}^{\prime}_{(k)} \mathbf{ b}) \Big)\mathbf{ x}_{(k)}  \Big{\}} \\
      &amp;  =\sum^K_{k=1} \Big(n_k\, \bar{y}_{(k)}-m_{(k)} \exp(\mathbf{ x}^{\prime}_{(k)} \mathbf{ b}) \Big)\mathbf{ x}_{(k)} =0. - (25)
\end{align}\]</span> Since <span class="math inline">\(n_k\, \bar{y}_{(k)}\)</span> in (25) represents the total loss count for the <span class="math inline">\(k\)</span>th risk class and <span class="math inline">\(m_{(k)}\)</span> is its total exposure, we see that for the Poisson regression the mle <span class="math inline">\(\mathbf{ b}\)</span> is the same whether if we use the individual data or the grouped data.</p>
<p><strong>Information matrix</strong><br />
Taking second derivatives to (23) gives the information matrix of the mle estimators, <span class="math display">\[\begin{equation}
\mathbf{ I}(\beta)=-\mathrm{E~}{\left( \frac{\partial^2}{\partial \beta\partial \beta^{\prime}}l(\beta) \right)}=\sum^n_{i=1}m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ \beta})\mathbf{ x}_i \mathbf{ x}_i^{\prime}=\sum^n_{i=1} {\mu}_i \mathbf{ x}_i \mathbf{ x}_i^{\prime}. - (26)
\end{equation}\]</span> For actual datasets, <span class="math inline">\({\mu}_i\)</span> in (26) is replaced with <span class="math inline">\(\hat{\mu}_i=m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ b})\)</span> to estimate the relevant variances and covariances of the mle <span class="math inline">\(\mathbf{ b}\)</span> or its functions.</p>
<p>For grouped datasets, we have <span class="math display">\[\begin{equation}
\mathbf{ I}(\beta)=\sum^K_{k=1} \Big{\{}\sum_{i \in C_k}m_i \exp(\mathbf{ x}^{\prime}_i \mathbf{ \beta})\mathbf{ x}_i \mathbf{ x}_i^{\prime} \Big{\}}=\sum^K_{k=1} m_{(k)} \exp(\mathbf{ x}^{\prime}_{(k)} \mathbf{ \beta})\mathbf{ x}_{(k)} \mathbf{ x}_{(k)}^{\prime}.
\end{equation}\]</span></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>For example, if there are 3 risk factors each of which the number of levels are 2, 3 and 4, respectively, we have <span class="math inline">\(k=(2-1)\times(3-1)\times (4-1)=6\)</span>.<a href="risk-classification.html#fnref1">↩</a></p></li>
<li id="fn2"><p>Preferring the multiplicative form to others (e.g., additive one) was already hinted in (4).<a href="risk-classification.html#fnref2">↩</a></p></li>
<li id="fn3"><p>corresponding to <span class="math inline">\(\texttt{VAgecat1}\)</span><a href="risk-classification.html#fnref3">↩</a></p></li>
<li id="fn4"><p>We use matrix derivative here.<a href="risk-classification.html#fnref4">↩</a></p></li>
</ol>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = '//lossdataanalytics.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="aggregate-loss-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="data-systems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/Chapters/RiskClassification.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

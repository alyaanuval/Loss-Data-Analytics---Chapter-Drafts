<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Data And Systems</title>
  <meta name="description" content="Data And Systems">
  <meta name="generator" content="bookdown 0.6.2 and GitBook 2.6.7">

  <meta property="og:title" content="Data And Systems" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Data And Systems" />
  
  
  

<meta name="author" content="Guojun Gan">


<meta name="date" content="2018-02-28">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  

<link rel="next" href="data-analysis-preliminary.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>1</b> Data</a><ul>
<li class="chapter" data-level="1.1" data-path="data.html"><a href="data.html#data-types-and-sources"><i class="fa fa-check"></i><b>1.1</b> Data Types and Sources</a></li>
<li class="chapter" data-level="1.2" data-path="data.html"><a href="data.html#data-structures-and-storage"><i class="fa fa-check"></i><b>1.2</b> Data Structures and Storage</a></li>
<li class="chapter" data-level="1.3" data-path="data.html"><a href="data.html#data-quality"><i class="fa fa-check"></i><b>1.3</b> Data Quality</a></li>
<li class="chapter" data-level="1.4" data-path="data.html"><a href="data.html#data-cleaning"><i class="fa fa-check"></i><b>1.4</b> Data Cleaning</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html"><i class="fa fa-check"></i><b>2</b> Data Analysis Preliminary</a><ul>
<li class="chapter" data-level="2.1" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#S:process"><i class="fa fa-check"></i><b>2.1</b> Data Analysis Process</a></li>
<li class="chapter" data-level="2.2" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#exploratory-versus-confirmatory"><i class="fa fa-check"></i><b>2.2</b> Exploratory versus Confirmatory</a></li>
<li class="chapter" data-level="2.3" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#supervised-versus-unsupervised"><i class="fa fa-check"></i><b>2.3</b> Supervised versus Unsupervised</a></li>
<li class="chapter" data-level="2.4" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#parametric-versus-nonparametric"><i class="fa fa-check"></i><b>2.4</b> Parametric versus Nonparametric</a></li>
<li class="chapter" data-level="2.5" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#S:expred"><i class="fa fa-check"></i><b>2.5</b> Explanation versus Prediction</a></li>
<li class="chapter" data-level="2.6" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#data-modeling-versus-algorithmic-modeling"><i class="fa fa-check"></i><b>2.6</b> Data Modeling versus Algorithmic Modeling</a></li>
<li class="chapter" data-level="2.7" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#big-data-analysis"><i class="fa fa-check"></i><b>2.7</b> Big Data Analysis</a></li>
<li class="chapter" data-level="2.8" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#reproducible-analysis"><i class="fa fa-check"></i><b>2.8</b> Reproducible Analysis</a></li>
<li class="chapter" data-level="2.9" data-path="data-analysis-preliminary.html"><a href="data-analysis-preliminary.html#ethical-issues"><i class="fa fa-check"></i><b>2.9</b> Ethical Issues</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html"><i class="fa fa-check"></i><b>3</b> Data Analysis Techniques</a><ul>
<li class="chapter" data-level="3.1" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#exploratory-techniques"><i class="fa fa-check"></i><b>3.1</b> Exploratory Techniques</a></li>
<li class="chapter" data-level="3.2" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#descriptive-statistics"><i class="fa fa-check"></i><b>3.2</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.2.1" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#principal-component-analysis"><i class="fa fa-check"></i><b>3.2.1</b> Principal Component Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#cluster-analysis"><i class="fa fa-check"></i><b>3.3</b> Cluster Analysis</a></li>
<li class="chapter" data-level="3.4" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#confirmatory-techniques"><i class="fa fa-check"></i><b>3.4</b> Confirmatory Techniques</a><ul>
<li class="chapter" data-level="3.4.1" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#linear-models"><i class="fa fa-check"></i><b>3.4.1</b> Linear Models</a></li>
<li class="chapter" data-level="3.4.2" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#generalized-linear-models"><i class="fa fa-check"></i><b>3.4.2</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="3.4.3" data-path="data-analysis-techniques.html"><a href="data-analysis-techniques.html#tree-based-models"><i class="fa fa-check"></i><b>3.4.3</b> Tree-based Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="some-r-functions.html"><a href="some-r-functions.html"><i class="fa fa-check"></i><b>4</b> Some R Functions</a></li>
<li class="chapter" data-level="5" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>5</b> Summary</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data And Systems</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="header">
<h1 class="title">Data And Systems</h1>
<h4 class="author"><em>Guojun Gan</em></h4>
<h4 class="date"><em>February 28, 2018</em></h4>
</div>
<div id="data" class="section level1">
<h1><span class="header-section-number">1</span> Data</h1>
<!-- % 7.1.3 - 7.1.6 data source, structure, storage, quality, preprocessing tools  inmon2014 -->
<!-- % 7.4.1 - 7.4.3 ethical (miles2014), governance, risks -->
<!-- % -->
<div id="data-types-and-sources" class="section level2">
<h2><span class="header-section-number">1.1</span> Data Types and Sources</h2>
<p>In terms of how data are collected, data can be divided into two types <span class="citation">(Hox and Boeije <a href="#ref-hox2005data">2005</a>)</span>: primary data and secondary data. Primary data are original data that are collected for a specific research problem. Secondary data are data originally collected for a different purpose and reused for another research problem. A major advantage of using primary data is that the theoretical constructs, the research design, and the data collection strategy can be tailored to the underlying research question to ensure that the data collected indeed help to solve the problem. A disadvantage of using primary data is that data collection can be costly and time-consuming. Using secondary data has the advantage of lower cost and faster access to relevant information. However, using secondary data may not be optimal for the research question under consideration.</p>
<p>In terms of the degree of organization of the data, data can be also divided into two types <span class="citation">(Inmon and Linstedt <a href="#ref-inmon2014">2014</a>; O’Leary <a href="#ref-leary2013bigdata">2013</a>; Hashem et al. <a href="#ref-hashem2015bigdata">2015</a>; Abdullah and Ahmad <a href="#ref-abdullah2013data">2013</a>; Pries and Dunnigan <a href="#ref-pries2015">2015</a>)</span>: structured data and unstructured data. Structured data have a predictable and regularly occurring format. In contrast, unstructured data are unpredictable and have no structure that is recognizable to a computer. Structured data consists of records, attributes, keys, and indices and are typically managed by a database management system (DBMS) such as IBM DB2, Oracle, MySQL, and Microsoft SQL Server. As a result, most units of structured data can be located quickly and easily. Unstructured data have many different forms and variations. One common form of unstructured data is text. Accessing unstructured data is clumsy. To find a given unit of data in a long text, for example, sequentially search is usually performed.</p>
<p>In terms of how the data are measured, data can be classified as qualitative or quantitative. Qualitative data is data about qualities, which cannot be actually measured. As a result, qualitative data is extremely varied in nature and includes interviews, documents, and artifacts <span class="citation">(Miles, Hberman, and Sdana <a href="#ref-miles2014">2014</a>)</span>. Quantitative data is data about quantities, which can be measured numerically with numbers. In terms of the level of measurement, quantitative data can be further classified as nominal, ordinal, interval, or ratio <span class="citation">(Gan <a href="#ref-gan2011">2011</a>)</span>. Nominal data, also called categorical data, are discrete data without a natural ordering. Ordinal data are discrete data with a natural order. Interval data are continuous data with a specific order and equal intervals. Ratio data are interval data with a natural zero.</p>
<p>There exist a number of data sources. First, data can be obtained from university-based researchers who collect primary data. Second, data can be obtained from organizations that are set up for the purpose of releasing secondary data for general research community. Third, data can be obtained from national and regional statistical institutes that collect data. Finally, companies have corporate data that can be obtained for research purpose.</p>
<p>While it might be difficult to obtain data to address a specific research problem or answer a business question, it is relatively easy to obtain data to test a model or an algorithm for data analysis. In nowadays, readers can obtain datasets from the Internet easily. The following is a list of some websites to obtain real-world data:</p>
<ul>
<li><p><strong>UCI Machine Learning Repository</strong> This website (url: <a href="http://archive.ics.uci.edu/ml/index.php" class="uri">http://archive.ics.uci.edu/ml/index.php</a>) maintains more than 400 datasets that can be used to test machine learning algorithms.</p></li>
<li><p><strong>Kaggle</strong> The Kaggle website (url: <a href="https://www.kaggle.com/" class="uri">https://www.kaggle.com/</a>) include real-world datasets used for data science competition. Readers can download data from Kaggle by registering an account.</p></li>
<li><p><strong>DrivenData</strong> DrivenData aims at bringing cutting-edge practices in data science to solve some of the world’s biggest social challenges. In its website (url: <a href="https://www.drivendata.org/" class="uri">https://www.drivendata.org/</a>), readers can participate data science competitions and download datasets.</p></li>
<li><p><strong>Analytics Vidhya</strong> This website (url: <a href="https://datahack.analyticsvidhya.com/contest/all/" class="uri">https://datahack.analyticsvidhya.com/contest/all/</a>) allows you to participate and download datasets from practice problems and hackathon problems.</p></li>
<li><p><strong>KDD Cup</strong> KDD Cup is the annual Data Mining and Knowledge Discovery competition organized by ACM Special Interest Group on Knowledge Discovery and Data Mining. This website (url: <a href="http://www.kdd.org/kdd-cup" class="uri">http://www.kdd.org/kdd-cup</a>) contains the datasets used in past KDD Cup competitions since 1997.</p></li>
<li><p><strong>U.S. Government’s open data</strong> This website (url: <a href="https://www.data.gov/" class="uri">https://www.data.gov/</a>) contains about 200,000 datasets covering a wide range of areas including climate, education, energy, and finance.</p></li>
<li><p><strong>AWS Public Datasets</strong> In this website (url: <a href="https://aws.amazon.com/datasets/" class="uri">https://aws.amazon.com/datasets/</a>), Amazon provides a centralized repository of public datasets, including some huge datasets.</p></li>
</ul>
</div>
<div id="data-structures-and-storage" class="section level2">
<h2><span class="header-section-number">1.2</span> Data Structures and Storage</h2>
<p>As mentioned in the previous subsection, there are structured data as well as unstructured data. Structured data are highly organized data and usually have the following tabular format:</p>
<p><span class="math display">\[\begin{matrix}
\begin{array}{lllll} \hline
 &amp; V_1 &amp; V_2 &amp; \cdots &amp; V_d \  
\\\hline
\textbf{x}_1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1d} \\
\textbf{x}_2 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2d} \\
\vdots &amp; \vdots &amp; \vdots &amp; \cdots &amp; \vdots \\
\textbf{x}_n &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{nd} \\
\hline
\end{array}
\end{matrix}
\]</span></p>
<p>In other words, structured data can be organized into a table consists of rows and columns. Typically, each row represents a record and each column represents an attribute. A table can be decomposed into several tables that can be stored in a relational database such as the Microsoft SQL Server. The SQL (Structured Query Language) can be used to access and modify the data easily and efficiently.</p>
<p>Unstructured data do not follow a regular format <span class="citation">(Abdullah and Ahmad <a href="#ref-abdullah2013data">2013</a>)</span>. Examples of unstructured data include documents, videos, and audio files. Most of the data we encounter are unstructured data. In fact, the term ``big data’’ was coined to reflect this fact. Traditional relational databases cannot meet the challenges on the varieties and scales brought by massive unstructured data nowadays. NoSQL databases have been used to store massive unstructured data.</p>
<p>There are three main NoSQL databases <span class="citation">(Chen et al. <a href="#ref-chen2014b">2014</a>)</span>: key-value databases, column-oriented databases, and document-oriented databases. Key-value databases use a simple data model and store data according to key-values. Modern key-value databases have higher expandability and smaller query response time than relational databases. Examples of key-value databases include Dynamo used by Amazon and Voldemort used by LinkedIn. Column-oriented databases store and process data according to columns rather than rows. The columns and rows are segmented in multiple nodes to achieve expandability. Examples of column-oriented databases include BigTable developed by Google and Cassandra developed by FaceBook. Document databases are designed to support more complex data forms than those stored in key-value databases. Examples of document databases include MongoDB, SimpleDB, and CouchDB. MongoDB is an open-source document-oriented database that stores documents as binary objects. SimpleDB is a distributed NoSQL database used by Amazon. CouchDB is an another open-source document-oriented database.</p>
</div>
<div id="data-quality" class="section level2">
<h2><span class="header-section-number">1.3</span> Data Quality</h2>
<p>Accurate data are essential to useful data analysis. The lack of accurate data may lead to significant costs to organizations in areas such as correction activities, lost customers, missed opportunities, and incorrect decisions <span class="citation">(Olson <a href="#ref-olson2003">2003</a>)</span>.</p>
<p>Data has quality if it satisfies its intended use, that is, the data is accurate, timely, relevant, complete, understood, and trusted <span class="citation">(Olson <a href="#ref-olson2003">2003</a>)</span>. As a result, we first need to know the specification of the intended uses and then judge the suitability for those uses in order to assess the quality of the data. Unintended uses of data can arise from a variety of reasons and lead to serious problems.</p>
<p>Accuracy is the single most important component of high-quality data. Accurate data have the following properties <span class="citation">(Olson <a href="#ref-olson2003">2003</a>)</span>:</p>
<ul>
<li>The data elements are not missing and have valid values.</li>
<li>The values of the data elements are in the right ranges and have the right representations.</li>
</ul>
<p>Inaccurate data arise from different sources. In particular, the following areas are common areas where inaccurate data occur:</p>
<ul>
<li>Initial data entry. Mistakes (including deliberate errors) and system errors can occur during the initial data entry. Flawed data entry processes can result in inaccurate data.</li>
<li>Data decay. Data decay, also known as data degradation, refers to the gradual corruption of computer data due to an accumulation of non-critical failures in a storage device.</li>
<li>Data moving and restructuring. Inaccurate data can also arise from data extracting, cleaning, transforming, loading, or integrating.</li>
<li>Data using. Faulty reporting and lack of understanding can lead to inaccurate data.</li>
</ul>
<p>Reverification and analysis are two approaches to find inaccurate data elements. To ensure that the data elements are 100% accurate, we must use reverification. However, reverification can be time-consuming and may not be possible for some data. Analytical techniques can also be used to identify inaccurate data elements. There are five types of analysis that can be used to identify inaccurate data <span class="citation">(Olson <a href="#ref-olson2003">2003</a>)</span>: data element analysis, structural analysis, value correlation, aggregation correlation, and value inspection</p>
<p>Companies can create a data quality assurance program to create high-quality databases. For more information about data quality issues management and data profiling techniques, readers are referred to <span class="citation">(Olson <a href="#ref-olson2003">2003</a>)</span>.</p>
</div>
<div id="data-cleaning" class="section level2">
<h2><span class="header-section-number">1.4</span> Data Cleaning</h2>
<p>Raw data usually need to be cleaned before useful analysis can be conducted. In particular, the following areas need attention when preparing data for analysis <span class="citation">(Janert <a href="#ref-janert2010">2010</a>)</span>:</p>
<ul>
<li><p><strong>Missing values</strong> It is common to have missing values in raw data. Depending on the situations, we can discard the record, discard the variable, or impute the missing values.</p></li>
<li><p><strong>Outliers</strong> Raw data may contain unusual data points such as outliers. We need to handle outliers carefully. We cannot just remove outliers without knowing the reason for their existence. Sometimes the outliers are caused by clerical errors. Sometimes outliers are the effect we are looking for.</p></li>
<li><p><strong>Junk</strong> Raw data may contain junks such as nonprintable characters. Junks are typically rare and not easy to get noticed. However, junks can cause serious problems in downstream applications.</p></li>
<li><p><strong>Format</strong> Raw data may be formated in a way that is inconvenient for subsequent analysis. For example, components of a record may be split into multiple lines in a text file. In such cases, lines corresponding to a single record should be merged before loading to a data analysis software such as R.</p></li>
<li><p><strong>Duplicate records</strong> Raw data may contain duplicate records. Duplicate records should be recognized and removed. This task may not be trivial depending on what you consider ``duplicate.’’</p></li>
<li><p><strong>Merging datasets</strong> Raw data may come from different sources. In such cases, we need to merge the data from different sources to ensure compatibility.</p></li>
</ul>
<p>For more information about how to handle data in R, readers are referred to <span class="citation">(Forte <a href="#ref-forte2015">2015</a>)</span> and <span class="citation">(Buttrey and Whitaker <a href="#ref-buttrey2017">2017</a>)</span>.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-hox2005data">
<p>Hox, Joop J., and Hennie R. Boeije. 2005. “Data Collection, Primary Versus Secondary.” In <em>Encyclopedia of Social Measurement</em>, 593–99. Elsevier.</p>
</div>
<div id="ref-inmon2014">
<p>Inmon, W.H., and Dan Linstedt. 2014. <em>Data Architecture: A Primer for the Data Scientist: Big Data, Data Warehouse and Data Vault</em>. Cambridge, MA: Morgan Kaufmann.</p>
</div>
<div id="ref-leary2013bigdata">
<p>O’Leary, D. E. 2013. “Artificial Intelligence and Big Data.” <em>IEEE Intelligent Systems</em> 28 (2): 96–99.</p>
</div>
<div id="ref-hashem2015bigdata">
<p>Hashem, Ibrahim Abaker Targio, Ibrar Yaqoob, Nor Badrul Anuar, Salimah Mokhtar, Abdullah Gani, and Samee Ullah Khan. 2015. “The Rise of ‘Big Data’ on Cloud Computing: Review and Open Research Issues.” <em>Information Systems</em> 47: 98–115.</p>
</div>
<div id="ref-abdullah2013data">
<p>Abdullah, M. F., and K. Ahmad. 2013. “The Mapping Process of Unstructured Data to Structured Data.” In <em>2013 International Conference on Research and Innovation in Information Systems (Icriis)</em>, 151–55.</p>
</div>
<div id="ref-pries2015">
<p>Pries, Kim H., and Robert Dunnigan. 2015. <em>Big Data Analytics: A Practical Guide for Managers</em>. Boca Raton, FL: CRC Press.</p>
</div>
<div id="ref-miles2014">
<p>Miles, Matthew, Michael Hberman, and Johnny Sdana. 2014. <em>Qualitative Data Analysis: A Methods Sourcebook</em>. 3rd ed. Thousand Oaks, CA: Sage.</p>
</div>
<div id="ref-gan2011">
<p>Gan, Guojun. 2011. <em>Data Clustering in C++: An Object-Oriented Approach</em>. Data Mining and Knowledge Discovery Series. Boca Raton, FL, USA: Chapman &amp; Hall/CRC Press. doi:<a href="https://doi.org/10.1201/b10814">10.1201/b10814</a>.</p>
</div>
<div id="ref-chen2014b">
<p>Chen, Min, Shiwen Mao, Yin Zhang, and Victor CM Leung. 2014. <em>Big Data: Related Technologies, Challenges and Future Prospects</em>. New York, NY: Springer.</p>
</div>
<div id="ref-olson2003">
<p>Olson, Jack E. 2003. <em>Data Quality: The Accuracy Dimension</em>. San Francisco, CA: Morgan Kaufmann.</p>
</div>
<div id="ref-janert2010">
<p>Janert, Philipp K. 2010. <em>Data Analysis with Open Source Tools</em>. Sebastopol, CA: O’Reilly Media.</p>
</div>
<div id="ref-forte2015">
<p>Forte, Rui Miguel. 2015. <em>Mastering Predictive Analytics with R</em>. Birmingham, UK: Packt Publishing.</p>
</div>
<div id="ref-buttrey2017">
<p>Buttrey, Samuel E., and Lyn R. Whitaker. 2017. <em>A Data Scientist�s Guide to Acquiring, Cleaning, and Managing Data in R</em>. Hoboken, NJ: Wiley.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>

<a href="data-analysis-preliminary.html" class="navigation navigation-next navigation-unique" aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
